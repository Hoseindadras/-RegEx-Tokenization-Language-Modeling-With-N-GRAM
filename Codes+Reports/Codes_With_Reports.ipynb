{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpUfyHm5H6m0"
      },
      "source": [
        "# Natural Language Processing (NLP)\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyWIgifpnOE2"
      },
      "source": [
        "## **RegEx & Tokenization & Language Modeling With N-GRAM**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Personal Information**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Name:** Hosein Dadras  \n",
        "\n",
        "**Personal Gmail:** Hoseindadras6@gmail.com  \n",
        "**ÙŽAcademic Mail:** Hoseindadras@ut.ac.ir  \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Table of Contents**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. [Chapter 1: RegEx & NER & Tokenization & EDs](#Chapter-1)\n",
        "    - [CH1-Data: About Dataset (ner.txt)](#CH1-data)\n",
        "    - [Part 1.1: Named Entity Recognition (NER) & Use RegEx in NER](#ner)\n",
        "    - [Part 1.2: Regular Expressions (RegEx)](#regex)\n",
        "    - [Part 1.3: Advantages & Disadvantages using RegEx in NER](#advantage_disadv)\n",
        "    - [Part 2.1: Rule-Based & ML-Based Tokenizations](#Tokenizer)\n",
        "    - [Part 2.2: Whitespace Tokenization](#Whitespace)\n",
        "    - [Part 3.1: Levenshtein & Damerau-Levenshtein Distances](#Levenshtein_DamerauLevenshtein_Distance)\n",
        "    - [Part 3.2: Implement of Distances](#implemented_Distances)\n",
        "2. [Chapter 2: N-Gram Language Models](#Chapter-2)\n",
        "    - [CH2-Data: About Dataset](#CH2-data)\n",
        "    - [Part 1.1: WordPiece](#Wordpiece_Tokenizer)\n",
        "    - [Part 1.2: Models Using WordPiece](#Models)\n",
        "    - [Part 1.3: Comparision with BPE](#BPE)\n",
        "    - [Part 2.1: Train Wordpiece Tokenizer on Ferdowsi](#Ferdowsi_Tokenizatoin)\n",
        "    - [Part 2.2: Test & Tokenizer With Trained Tokenizer](#Tokenize)\n",
        "    - [Part 3.1: N-Gram & Previous Tokenizer](#NGRAM_Pre_Tok)\n",
        "    - [Part 3.2: Train Model & Text Generation](#Train&Gernerate)\n",
        "    - [Part 3.3: Big N in N-GRAM & Challenges](#Big_N_in_NGRAM)\n",
        "    - [Part 3.A: Analysis of Generated Text](#Analysis_Gernerated)\n",
        "    - [Part 4.1: Perplexity Criterion](#perplexity-criterion)\n",
        "    - [Part 4.2: Perplexity on Hafez & Modern Poem](#Pre_NGRAM_Compares)\n",
        "    - [Paer 4.A: Analysis of Perplexities](#Analyze_Perplex)\n",
        "3. [Chapter 3: N-Gram as a Classifier](#Chapter-3)\n",
        "    - [Part 1.1: N-Gram As a Classifier](#NGRAM_Classifier)\n",
        "    - [Part 1.2: Big N & Low Data](#bign_lowdata)\n",
        "    - [Part 2.1: BPE Tokenizer](#BPE_Tokenizer)\n",
        "    - [Part 2.2: Tokenize the Dataset](#Tokenize_BPE)\n",
        "    - [Part 3.1: N-GRAM & Classification](#Classification_NGRAM)\n",
        "    - [Part 3.2: 2-3-GRAM](#SplitData_32Gram)\n",
        "    - [Part 3.3: Criterion on Models](#Criterion_Models)\n",
        "    - [Part 3.4: Results Analysis](#Analysis)\n",
        "4. [Chapter 4: Image tokenization](#Chapter-4)\n",
        "    - [Part 1.1: Image Tokenization & Vision Transformer](#IT_VT)\n",
        "    - [Part 1.2: MNIST & KMeans](#Kmeans)\n",
        "    - [Part 2.1: 4-GRAM](#4Gram_Image)\n",
        "    - [Part 2.2: Accuracy](#accuracy)\n",
        "    - [Part 2.plot: Plot-predictions](#plot)\n",
        "5. [References](#ref)\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrNzafCWY3rh"
      },
      "source": [
        "\n",
        "## **Chapter 1: RegEx & NER & Tokenization & EDs**<a name=\"Chapter-1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Dataset ner.txt**\n",
        "- **Regular Expressions (RegEx)**\n",
        "- **Named Entity Recognition (NER)**\n",
        "    - **Email Extraction**\n",
        "    - **Urls Extraction**\n",
        "    - **Phone Numbers Extraction**\n",
        "- **Tokenization**\n",
        "    - **Rule-based Tokenizers**\n",
        "        - **Whitespace Tokenizer**\n",
        "    - **ML-based Tokenizers**\n",
        "- **Edit Distance** \n",
        "    - **Levenshtein Distance**\n",
        "    - **Damerau-Levenshtein Distance** \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPx0CS-2mCWo"
      },
      "source": [
        "### CH1-Data: **About Dataset (ner.txt)**<a name=\"CH1-data\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset provided is a textual document that focuses on **trends** and **innovations** in the **Digital Marketing Industry**. \n",
        "\n",
        "It contains valuable information about **cutting-edge marketing strategies**, **technological advancements**, and **company profiles** shaping the future of digital advertising."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-yURHt-mHkJ"
      },
      "source": [
        "\n",
        "#### **Some information about Dataset**\n",
        "- **Topics Covered:**\n",
        "    - The text covers a wide range of topics in digital marketing, including:\n",
        "        - **AI(Artificial Intelligence)**\n",
        "        - **AR(Augmented Realistic)** \n",
        "        - **programmatic advertising**\n",
        "        - **Influencer marketing** \n",
        "        - **customer experience optimization**\n",
        "    - Companies and organizations at the forefront of these trends include:\n",
        "        - **VRInnovations**\n",
        "        - **TechAdvisors**\n",
        "        - **DeepAd**\n",
        "\n",
        "- **Entities Present:**\n",
        "    - **Companies & Organizations:** Various marketing firms are mentioned, providing business context.\n",
        "    - **Contact Information:** \n",
        "        - **Emails** \n",
        "        - **phone numbers**\n",
        "        - **website links are useful for networking and outreach**\n",
        "\n",
        "- **Structured Data:**\n",
        "    - **Emails:** Various formats are included, associated with individuals or departments.\n",
        "    - **Phone Numbers:** Multiple international and domestic phone numbers.\n",
        "    - **URLs:** Corporate websites, blogs, and research papers.\n",
        "\n",
        "- **An Example of Dataset:**\n",
        "    \n",
        "    - **To stay ahead of the curve, businesses must stay informed about the legal regulations surrounding digital marketing. In an article by LegalEagle (visit: https://www.legaleagle.org/marketing-laws), experts warned of the stringent data privacy laws being implemented in regions like the EU. For more legal insights, contact their team at info@legaleagle.org or call +33 1 2345 6789.**\n",
        "\n",
        "    - **Lastly, customer experience will continue to shape the future of digital marketing. Companies like CXInnovators (website: https://www.cxinnovators.com) are pioneering new ways to create seamless, personalized customer journeys. Their CEO, Paul Jenkins, can be reached at paul.jenkins@cxinnovators.com or at +1-646-555-9988 for more insights. The CXInnovators blog, updated weekly, provides valuable tips on enhancing customer experience at https://www.cxinnovators.com/blog.**\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL2ChPe3YeV9"
      },
      "source": [
        "### Part 1.1: **Named Entity Recognition (NER)** <a name=\"ner\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Named Entity Recognition (NER)**-also called entity chunking or entity extraction\n",
        "\n",
        "- Is a component of NLP that identigies predefined categories of objects in a body of text. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Human language are complex. They get even more complex when context shows up on the horizon. \n",
        "\n",
        "- Let's take the name 'Lincoln', for example. Some people with instantly think of the 16th president of the USA, a towering historical figure. \n",
        "\n",
        "- For others, however, this will be a car manufacturer with the same name. A simple word, it has different meanings. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- As humans, we discern meanings and catogories effortlessly. This is a testment to our intuitive grasp of the world around us.\n",
        "\n",
        "- When it comes to computers, this seemingly straightforward task becomes a challenge packed with ambiguity.  \n",
        "\n",
        "- Such complexities underscore the need for **robust Named Entity Recognition or NER-a mechanism** by which **we teach machines to understand various linguistic nuances**. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **NER** is a subfield of NLP that focuses on **identifying** and **classifying** **specific data points from textual content**. \n",
        "\n",
        "- NER works with salient details of the text, known as **Named Entities**\n",
        "    - Single words\n",
        "    - Pharases\n",
        "    - Sequences of words\n",
        "    \n",
        "    \n",
        "    by identifying and catogorizing them into predefined groups\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The Categories encompass a diverse range of subjects present within the text, including:\n",
        "    - **Individuals' names**\n",
        "    - **geographic locations**\n",
        "    - **Organizational names** \n",
        "    - **Dates**\n",
        "    - **Events**\n",
        "    - Even specific quantitative values such as **money** and **percentages**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Key Concept of NER**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **POS tagging:**\n",
        "    \n",
        "    - Standing for **part-of speech**, this process assigns labels to words in a text corresponding to their specific part of speech, such as adjectives, verbs, or nauns. \n",
        "\n",
        "- **Corpus:** \n",
        "    - This is a collection of texts used for linguistic analysis and training NER models. A Corpus can range from a set of news articles to academic journals or even social mediaa posts. \n",
        "\n",
        "- **Chunking:** \n",
        "    - This is an NLP tech that groups individual words or pharases into \"Chunks\" based on their syntactic roles, creating meaningful clusters like noun phrases or verb phrases. \n",
        "\n",
        "- **Word Embedding:** \n",
        "    - These are dense vector representations of words, capturing their semantic meanings. Word embeddings translate words or phrases into numerical vectors of fixed size, making it easier for machine learning models to process. Tools like Word2Vec, and Glove are popular for generating such embeddings, and they help in understanding the context and relationships between words in a text. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **NER example**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Consider the sentence: \n",
        "    - **\"Hosein from the AI department said that The Parsian Tehran was a great hotel option to stay in Tehran.\"**\n",
        "    \n",
        "- Now --**With NER**:\n",
        "    - **Hosein(PERSON) from the AI department said The Parsian(ORG) Tehran was a great hotel option to stay in Tehran(GPE)**\n",
        "    \n",
        "- In this sentences:\n",
        "    - **\"Hosein\"** is labeled as **PERSON**, indicating that it is an entity representing a **preson's name**. \n",
        "    \n",
        "    - **The Parsian** is tagged as **ORG**, which stands for **Organization**. This means it is recognized as an entity that refers to campanies, agencies, institutions, etc.\n",
        "    \n",
        "    - **\"Tehran\"** has been classified as **GPE**, which stands for **GeoPolitical Entity**. GPEs represent conutries, cities, states, or any other reqions with a defined boundary or governance.\n",
        "    \n",
        "\n",
        "In essence, if we aim to discern a text's **Who, Where, What, and When**, **NER** is the technique to use.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **How NER works?**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Two Steps:**    \n",
        "    \n",
        "    - **Step 1:**\n",
        "        Identifying entities within the text.\n",
        "    \n",
        "    - **Step 2:**\n",
        "        Catogorizing these entities into distinct groups (Classifying entities into categories).\n",
        "\n",
        "---\n",
        "- **An Example:**\n",
        "    - **Microsoft announced a new AI tool in seatle**\n",
        "\n",
        "        - **Step 1:**\n",
        "\n",
        "            - **POS**\n",
        "\n",
        "                - Microsoft/NNP announced/VBD a/DT new/JJ AI/NN tool/NN in/IN seattle/NNP\n",
        "            \n",
        "                - **/NNP (Proper Noun, Singular)**: Refers to proper nouns that are singular. Proper nouns are specific names of people, places, or organizations.\n",
        "                    - \"Microsoft\", \"John\", \"Paris\"\n",
        "            \n",
        "                - **/VBD (Verb, Past Tense)**: Refers to verbs in their past tense form.\n",
        "                    - \"ran\", \"walked\", \"announced\"\n",
        "            \n",
        "                - **DT (Determiner)**: Refers to determiners, which introduce nouns and help specify them.\n",
        "                    - \"the\", \"a\", \"an\", \"this\"\n",
        "            \n",
        "                - **JJ (Adjective)**: Refers to adjectives, which describe or modify nouns.\n",
        "                    - \"beautiful\", \"red\", \"quick\"\n",
        "            \n",
        "                - **NN (Noun, Singular or Mass)**: Refers to singular nouns or mass nouns. A noun represents a person, place, thing, or idea.\n",
        "                    - \"dog\", \"city\", \"water\"\n",
        "            \n",
        "                - **IN (Preposition or Subordinating Conjunction)**: Refers to prepositions (words that link nouns, pronouns, or phrases to other words) or subordinating conjunctions.\n",
        "                    - \"in\", \"on\", \"at\", \"because\"\n",
        "                    \n",
        "        - **Step 2:**\n",
        "\n",
        "            - **Chunking**\n",
        "            \n",
        "                - [NP Microsoft] [VP announced] [NP a new AI tool] [PP in Seattle]\n",
        "                \n",
        "                - **NP (Noun Pharases)**\n",
        "                - **VP (Verbal Pharases)**\n",
        "                - **PP (Propositional Pharases)**\n",
        "\n",
        "        - **Step 3:**\n",
        "\n",
        "            - **NER**\n",
        "            \n",
        "                - \"Microsoft\" -> ORGANIZATION\n",
        "            \n",
        "                - \"Seatle\" -> LOCATION\n",
        "            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Approaches to NER**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NER has evolved significantly over the years, with multiple approaches being developed to tackle its challenges to tackle its challenges.\n",
        "\n",
        "- **Common NER methods :**\n",
        "\n",
        "    - **The rule-based methods of NER**\n",
        "    \n",
        "    - **Machine learning-based method of NER**\n",
        "    \n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qfi9SI5tmTr1"
      },
      "source": [
        "\n",
        "#### **The Core Goals of NER**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "- **Facilitating Information Extraction**\n",
        "\n",
        "   - NER plays a critical role in extracting meanings, structured data from vast amounts of unstructured text. Whether it's legal documents, research papers, or news articles, NER helps identify and pull out important entities like people, organizations, or locations, transforming raw text into actionable information. This is particulrly useful in areas like **AI Developing, Business Intelligence, Context Analysis, and Data Mining**.\n",
        "\n",
        "- **Streamlining Data Orginization and Indexing** \n",
        "\n",
        "    - NER assists in organizing and categorizing large datasets by tagging essential entities. This structured tagging makes it easier to organize informatoin systematically, enabling more efficient indexing and retrival of relevant data. Industries dealing with high volumes of data--Such as **Healthcare, Finance, and Customer Support**--benefit from this enhanced ability to manage content more effectively.\n",
        "\n",
        "- **Enhancing Search Engine Functionality** \n",
        "\n",
        "    - One of the primary uses of NER is to improve the accuracy and relevance of search results. By recognizing specific entities within a query, search engines can deliver more precise information that aligns closely with uset intent. This capability is especially valuable in specialized search engines, such as those used in **Academic or Legal Research**, where identifying proper nouns and specific term is critical.\n",
        "\n",
        "- **Improving Content Recommendation Systems** \n",
        "\n",
        "    - NER enables recommendation engines to become more effective by identifying entities that reflect user preferences. For instance, in **Entertainment Platforms or News Aggregation Services**, NER can identify key interest (e.g., **Favorite actors, Companies, or Places**) and tailor content recommendations based on these identified entities, resulting in a more personalized user experience.\n",
        "\n",
        "- **Refining Sentiment and Opinion Analysis** \n",
        "\n",
        "    - In the context of **Social Media monitoring or customer feedback analysis**, NER allows organizations to focus sentiment analysis on specific entities like **Brands, Products, or Public Figures**. By extracting entities from user comments or reviews, companies can gain deeper insights into how these specific entities are percieved, helping them make informed Business or reputational decisions. \n",
        "\n",
        "- **Optimizing Question-Answering Systems** \n",
        "\n",
        "    - NER is instrumental in enhancing the accuracy and performance of QA Systems, such as **Virtual Assistants and ChatBots**. By indentifying the entities within a user's query, the system can deliver more focused and accurate answers, improving the overall quality and efficiency of responses. This is particularly relevant in **Customer Service, Healthcare, and Educational Platforms** where quick and correct responses are essential.\n",
        "\n",
        "- **Preserving Key Information in Machine Translation and Summerization** \n",
        "\n",
        "    - When translating  text between languages or summerizing lengthy documents, NER ensures that critical entities--such as Names, Dates, and Locations--are correctly preserved. This is cruicial in applications like **Legal or Medical Translations**, where the misidentification of an entities could lead to serious errors. Similarly, in \"Summerization\" taks, NER helps retain **The Most Important Information**, ensuring summaries remain relevant accurate.\n",
        "\n",
        "- **Supporting Financial & Legal Analytics** \n",
        "\n",
        "    - In highly regulated industries like **Finance and Law**, NER is used to extract and analyze key information from Documents, such as **Contracts, Financial, Reports, or Legal Filings**. NER can quickly identify entities suuch as **Company Names, Monetary Values, Dates, or Legal Preference**, facilitating **Faster Decision-making, Compliance Checks, and Trend analysis**. This automation reduces manual labor and increase accuracy, making it a valuable tool for professinals in these sectors. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST4HNQmBmXbo"
      },
      "source": [
        "#### **Challenges in NER**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Handling Ambiguity in Entity Identification**\n",
        "\n",
        "Ambiguity is one of the primary challenges in NER, where the same word can represent multiple different entities depending on the context. For instance, \"Apple\" could refer to the technology company or the fruit, and \"IRAN\" might refer a person, a country, or a state. Resolving these ambiguities requires sophisticated disambiguation algorithms that can analyze the context in which the entity appears, ensuring that the correct entity is identified. This challenge often necessitatess the integration of external knowledge based, such as **Wikipedia or Domain-Specific Ontologies**, to provide clarity and accurate entity classification.\n",
        "\n",
        "- **Navigating Context Sensitivity in Entity Recognition**\n",
        "\n",
        "Determining whether a word should be classified as an entity or a common noun requires a deep understanding of context. For example the word \"Amazon\" can refer to A Company, A River (In South America), A Rainforest, or A General noun depending on the surronding text. NER systems must be capable of distinguishing when a word represents a specific entity versus when it is used in a more generic sense.\n",
        "\n",
        "- **Addressing Domain-Specific Adaptations for Specialized Fields**\n",
        "\n",
        "NER systems face significant challenges when applied to domain-specific texts, such as **Legal, Medical, or Scientific documents**. Each field comes with its own set of **Terminologies, Abbreviations, and Naming conventions** that may not be easily recognized by generic NER models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvZUt48oZPLO"
      },
      "source": [
        "### Part 1.2: **Regular Expressions (RegEx)** <a name=\"regex\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zK6BInPlPiA"
      },
      "source": [
        "#### **Import libraries & Load Data & Visualizations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nc3jBz0lvEY"
      },
      "source": [
        "##### **Import necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "84gOOCynlc3P"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgbtB0H7gf7J"
      },
      "source": [
        "##### **Loading the Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hQFsTc56jR5J"
      },
      "outputs": [],
      "source": [
        "file_path = rXXXX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fCuVYXjLjUJy"
      },
      "outputs": [],
      "source": [
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    text_data = file.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugwk8PjEgvPc"
      },
      "source": [
        "##### **Data Visualization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Splitting the Text into Sequences**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mq6emjPQjX9h"
      },
      "outputs": [],
      "source": [
        "def split_into_sentences(text):\n",
        "    sentence_endings = re.compile(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s')\n",
        "    sentences = sentence_endings.split(text)\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Negative Lookbehinds**\n",
        "\n",
        "- **Positive Lookbehind**\n",
        "\n",
        "- **Whitespace Matching**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **(?<! \\w\\.\\w. )**\n",
        "\n",
        "To avoid splitting sentences when periods occur in certain abbreviations or initials. \n",
        "\n",
        "This is a **Negative lookbehind assertion**, which checks for a specific pattern before the current position and ensures that pattern is not present. \n",
        "\n",
        "- **\"\\w\":** Represents any word character (letter, digits, underscores).\n",
        "\n",
        "- **\"\\.\\w.\":** Is checking for a period between two word characters. For example, in **J.R.**, this would match because there are periods surrounded by single letters.\n",
        "\n",
        "Thise prevents splitting on periods used in abbreviations or initial like **Dr. , e.g., or J.k.**. Without this, sentences would be wrongly split at these points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **( ?<! [A-Z][a-z]\\.)**\n",
        "\n",
        "To avoid splitting sentences after initials that may not involve middle names but part of a proper name (**e.g., Mr. or Mrs.**)\n",
        "\n",
        "This is another **Negative Lookbehind Assertion**.\n",
        "\n",
        "- **\"[A-Z]\":** Looks for a capital letter (indicating a potential abbreviation or title).\n",
        "\n",
        "- **\"[a-z]\":** Chacks for a lowercase letter followed by a period.\n",
        "\n",
        "This prevents splitting after title-like abbreviations, such as **Mr. , Mrs. , Dr. or Ms.**.Without this, the RegEx might incorrectly assume that **Mr.** is the end of a sentence, when it's actually part of a title."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **(?<= \\. | \\?)**\n",
        "\n",
        "To ensure that the split occurs after sentence-ending punctuation, specifically a period (.) or a question mark (?).\n",
        "\n",
        "This is a **Positive Lookbehind Assertion**, which meaans the RegEx is only interested in places where a period or question mark precedes the whitespace.\n",
        "\n",
        "- **\"\\.\":** Checks for a period.\n",
        "\n",
        "- **\"\\?\":** Checks for a question mark.\n",
        "\n",
        "- **\"(?<=\\.|\\?)\":** Ensures that the match only occurs if the current position follows a period or question mark."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **\\s**\n",
        "\n",
        "To split based on whitespace after a period or question mark.\n",
        "\n",
        "The **\\s** matches any whitespace character, including spaces, tabs, or newlines. This ensures that sentences are split wherever there is a space after the period or question mark, which is a common indicator that a new sentence is starting \n",
        "\n",
        "For example, \"This is a sentence. This is another sentence\", the RegEx will split after the space following the period."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Splitting the Text into Paragraphs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "eYfkxnW3jZRN"
      },
      "outputs": [],
      "source": [
        "def split_into_paragraphs(text):\n",
        "    paragraphs = text.split('\\n\\n')\n",
        "    return paragraphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function splits the input text into paragraphs. It assumes that paragraphs are separated by double newline characters **(\\n\\n)**. Each block of text between these newline characters is treated as a paragraph.\n",
        "\n",
        "By splitting the text in this manner, we can preserve the structure of the input and retrieve entire paragraphs, which is useful when performing operations that require context beyond individual sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Selecting a Random Sentence**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "S5D67puujbCS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample Sentence:\n",
            "Lastly, customer experience will continue to shape the future of digital marketing.\n"
          ]
        }
      ],
      "source": [
        "sentences = split_into_sentences(text_data)\n",
        "sample_sentence = random.choice(sentences).strip()\n",
        "\n",
        "print(\"Sample Sentence:\")\n",
        "print(sample_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After splitting the text into sentences using the split_into_sentences function, this section selects a random sentence from the list of sentences using the **random.choice() function**.\n",
        "\n",
        "The selected sentence is then stripped of any leading or trailing whitespace to ensure that the output is clean. This random sampling can be useful for quick visualization or inspection of the text data to see how the sentences are being split and how they look.\n",
        "\n",
        "The result is printed as a \"**Sample Sentence**\". which can give an idea of the sentence structure within the text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Selecting a Random Paragraph**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hvBm1-OQjccV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample Paragraph:\n",
            "Meanwhile, email marketing continues to be an effective tool for brands to communicate with customers directly. MailMasters (website: http://www.mailmasters.com) has been at the forefront of this domain. They recently introduced a new tool for analyzing open rates and customer engagement. You can contact their CEO, Alice Peters, at alice.p@mailmasters.com or give her a call at +1-212-555-6677. For sales inquiries, you can also reach out to their team via sales@mailmasters.com.\n"
          ]
        }
      ],
      "source": [
        "paragraphs = split_into_paragraphs(text_data)\n",
        "sample_paragraph = random.choice(paragraphs).strip()\n",
        "\n",
        "print(\"\\nSample Paragraph:\")\n",
        "print(sample_paragraph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similar to the previous step, this section selects a random paragraph from the text after splitting it into paragraphs using the **split_into_paragraphs function**.\n",
        "\n",
        "By using **random.choice()**, the function retrieves one paragraph randomly, which is then stripped of any leading or trailing whitespace. This allows for a quick examination of the paragraph structure in the text.\n",
        "\n",
        "The paragraph is printed as a \"**Sample Paragraph**\", which can provide insights into how the text is organized at a higher level than individual sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL561ykwkmHI"
      },
      "source": [
        "#### **RegEx for Emails**\n",
        "\n",
        "The regular expression used for email extraction:\n",
        "[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+.[A-Z|a-z]{2,}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IXJ6TvoOkmdZ"
      },
      "outputs": [],
      "source": [
        "def extract_emails(text):\n",
        "\n",
        "    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
        "    emails = re.findall(email_pattern, text)\n",
        "\n",
        "    return emails"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "46IiZ-SPkrON"
      },
      "outputs": [],
      "source": [
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "\n",
        "    text = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Jcou1YinksgP"
      },
      "outputs": [],
      "source": [
        "emails = extract_emails(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8_pz_eAoktiz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted Emails:\n",
            "info@vrinnovations.com\n",
            "john.martinez@techadvisors.net\n",
            "support@innovateads.co\n",
            "alice.p@mailmasters.com\n",
            "sales@mailmasters.com\n",
            "director@socialbuzz.org\n",
            "support@deepad.ai\n",
            "info@legaleagle.org\n",
            "partners@influenceme.io\n",
            "contact@brandvision.com\n",
            "hello@mobilemarketersinc.com\n",
            "paul.jenkins@cxinnovators.com\n",
            "info@digitalfuture2025.com\n"
          ]
        }
      ],
      "source": [
        "print(\"Extracted Emails:\")\n",
        "for email in emails:\n",
        "    print(email)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xws01fupZVMR"
      },
      "source": [
        "#### **RegEx for URLs**\n",
        "\n",
        "The regular expression used for URL extraction:\n",
        "https?://^\\s,).])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "inubEAGZZY0O"
      },
      "outputs": [],
      "source": [
        "def extract_urls(text):\n",
        "\n",
        "    url_pattern = r'https?://[^\\s,)]+(?:/[^\\s,).]*)*'\n",
        "\n",
        "    urls = re.findall(url_pattern, text)\n",
        "    urls = [url.rstrip('.') for url in urls]\n",
        "\n",
        "    return urls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Vzanv5BwjwGH"
      },
      "outputs": [],
      "source": [
        "urls = extract_urls(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yjVrHjp5jxCt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted URLs:\n",
            "https://www.digitalfuture2025.com\n",
            "http://www.techadvisors.net\n",
            "https://www.innovateads.co\n",
            "https://www.innovateads.co/blog\n",
            "http://www.mailmasters.com\n",
            "https://www.socialbuzz.org\n",
            "http://www.deepad.ai\n",
            "http://www.deepad.ai/research\n",
            "https://www.legaleagle.org/marketing-laws\n",
            "http://www.influenceme.io\n",
            "https://www.brandvision.com\n",
            "http://www.mobilemarketersinc.com\n",
            "https://www.cxinnovators.com\n",
            "https://www.cxinnovators.com/blog\n",
            "https://www.digitalfuture2025.com/articles\n"
          ]
        }
      ],
      "source": [
        "print(\"Extracted URLs:\")\n",
        "for url in urls:\n",
        "    print(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9-_Wi2EZZJ5"
      },
      "source": [
        "#### **RegEx for Phone Numbers**\n",
        "\n",
        "The regular expression used for phone number extraction:\n",
        "+\\d{1,3}[\\s-]?\\d{1,3}[\\s-]?\\d{3,4}[\\s-]?\\d{4}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "khAbQdFnZb5z"
      },
      "outputs": [],
      "source": [
        "def extract_phone_numbers(text):\n",
        "    phone_pattern = r'\\+\\d{1,3}[\\s-]?\\d{1,3}[\\s-]?\\d{3,4}[\\s-]?\\d{4}'\n",
        "    phone_numbers = re.findall(phone_pattern, text)\n",
        "    return phone_numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "QYZCF0YKj0Nc"
      },
      "outputs": [],
      "source": [
        "phone_numbers = extract_phone_numbers(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "DPwztFn0j1_A"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted Phone Numbers:\n",
            "+1-800-555-1234\n",
            "+44 20 7946 0958\n",
            "+1-310-555-7890\n",
            "+1-212-555-6677\n",
            "+1-718-555-9988\n",
            "+49 30 1234 5678\n",
            "+33 1 2345 6789\n",
            "+61 3 9876 5432\n",
            "+1-202-555-2244\n",
            "+1-415-555-3344\n",
            "+1-646-555-9988\n",
            "+1-888-555-1234\n"
          ]
        }
      ],
      "source": [
        "print(\"Extracted Phone Numbers:\")\n",
        "for number in phone_numbers:\n",
        "    print(number)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3aL4nC_j5ZW"
      },
      "source": [
        "#### Now, **All** in One definition :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "5hEttfPwj7qb"
      },
      "outputs": [],
      "source": [
        "def extract_information(text):\n",
        "\n",
        "    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
        "    emails = re.findall(email_pattern, text)\n",
        "\n",
        "    url_pattern = r'https?://[^\\s,)]+(?:/[^\\s,).]*)*'\n",
        "    urls = re.findall(url_pattern, text)\n",
        "    urls = [url.rstrip('.') for url in urls]\n",
        "\n",
        "    phone_pattern = r'\\+\\d{1,3}[\\s-]?\\d{1,3}[\\s-]?\\d{3,4}[\\s-]?\\d{4}'\n",
        "    phone_numbers = re.findall(phone_pattern, text)\n",
        "\n",
        "    return emails, urls, phone_numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9HnudY9Wj9Bv"
      },
      "outputs": [],
      "source": [
        "def display_extracted_information(emails, urls, phone_numbers):\n",
        "\n",
        "    print(\"Extracted Emails:\")\n",
        "    for email in emails:\n",
        "        print(email)\n",
        "\n",
        "    print(\"\\nExtracted URLs:\")\n",
        "    for url in urls:\n",
        "        print(url)\n",
        "\n",
        "    print(\"\\nExtracted Phone Numbers:\")\n",
        "    for number in phone_numbers:\n",
        "        print(number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "byBHDPJxj-zv"
      },
      "outputs": [],
      "source": [
        "emails, urls, phone_numbers = extract_information(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Ank7rLuZkAC9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted Emails:\n",
            "info@vrinnovations.com\n",
            "john.martinez@techadvisors.net\n",
            "support@innovateads.co\n",
            "alice.p@mailmasters.com\n",
            "sales@mailmasters.com\n",
            "director@socialbuzz.org\n",
            "support@deepad.ai\n",
            "info@legaleagle.org\n",
            "partners@influenceme.io\n",
            "contact@brandvision.com\n",
            "hello@mobilemarketersinc.com\n",
            "paul.jenkins@cxinnovators.com\n",
            "info@digitalfuture2025.com\n",
            "\n",
            "Extracted URLs:\n",
            "https://www.digitalfuture2025.com\n",
            "http://www.techadvisors.net\n",
            "https://www.innovateads.co\n",
            "https://www.innovateads.co/blog\n",
            "http://www.mailmasters.com\n",
            "https://www.socialbuzz.org\n",
            "http://www.deepad.ai\n",
            "http://www.deepad.ai/research\n",
            "https://www.legaleagle.org/marketing-laws\n",
            "http://www.influenceme.io\n",
            "https://www.brandvision.com\n",
            "http://www.mobilemarketersinc.com\n",
            "https://www.cxinnovators.com\n",
            "https://www.cxinnovators.com/blog\n",
            "https://www.digitalfuture2025.com/articles\n",
            "\n",
            "Extracted Phone Numbers:\n",
            "+1-800-555-1234\n",
            "+44 20 7946 0958\n",
            "+1-310-555-7890\n",
            "+1-212-555-6677\n",
            "+1-718-555-9988\n",
            "+49 30 1234 5678\n",
            "+33 1 2345 6789\n",
            "+61 3 9876 5432\n",
            "+1-202-555-2244\n",
            "+1-415-555-3344\n",
            "+1-646-555-9988\n",
            "+1-888-555-1234\n"
          ]
        }
      ],
      "source": [
        "display_extracted_information(emails, urls, phone_numbers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHyVQm2MZcLm"
      },
      "source": [
        "### Part 1.3: **Advantages and Disadvantages of Using RegEx in NER**<a name=\"advantage_disadv\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Advantages:**\n",
        "- **Simplicity and Speed:** Useful for well-defined formats.\n",
        "- **Rule-Based Control:** Complete control over patterns to match.\n",
        "- **No Training Data Needed:** Immediate extraction without training.\n",
        "- **Language and Domain Independence:** Works across different languages.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Disadvantages:**\n",
        "- **Limited Flexibility and Scalability:** Difficulty in handling variations.\n",
        "- **Ambiguity Handling:** Inability to resolve contextual ambiguity.\n",
        "- **Brittle and Hard to Maintain:** Patterns may break with format changes.\n",
        "- **Poor Handling of Complex Entities:** Difficulties in recognizing complex, non-standardized entities.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxKYy3-RnxgB"
      },
      "source": [
        "### Part 2.1: **Rule-Based & ML-Based Tokenizations** <a name=\"Tokenizer\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Tokenization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the field of NLP, tokenization is the initial step in processing text, where a large body of text is split into smaller, manageable units known as tokens. These tokens can represent words, subwords, punctuations marks, or even sentences, depending on the task. Among various tokenization methods, **Rule-Based tokenization** employs a set of predefined rules to determine the boundaries of tokens within a text. It is particularly suitable for cases where specific language patterns and structures are predictable, offering precision and control in tokenizing text. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **What is Rule-Based Tokenization?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Rule-Based tokenization is a method of segmenting text into tokens using language-specific rules. These rules can involve splitting text at whitespaces, handling punctuation marks, managing contractions, and identifying boundaries between different linguistic units. The primary goal is to accurately define how words and symbols are seperated while considering the nuances of grammer and language structure. Unlike statistical or machine learning-based approaches, rule-based tokenizatoin does not require training data but instead relies on manually craftedd rules. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Techniques in Rule-Based Tokenization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Rule-Based tokenization uses various tech to handle the complexities of natural language, including:\n",
        "\n",
        "- **Whitespace Tokenization:** The simplest form of rule-based tokenization splits text whenever a space is encountered. This approach is effective for languages like English and Farsi, where words are seperated by spaces. However, it may be insufficient for language that do not use spaces, such as Chinese of Japanses. \n",
        "\n",
        "- **Punctuation Handling:** Effective tokenizer often need to distinguish between punctuation that seperates sentences and that which is part of abbreviationis or contractions. For instance, a rule can be set to split text at periods, exclamation marks, or questoin marks, while retaining periods in abbreviations like**Dr.** or **e.g.,**.\n",
        "\n",
        "- **Regular Expressions (RegEx):** RegEx provide a powerful mechanism for pattern matching, allowing the creation of sophosticated rules. RegEx can be used to identify patterns such as dates, email addresses, phone numbers, and other entities that require specific handling during tokenization. \n",
        "\n",
        "- **Word Boundaries Identification:** Identifying word boundaries is essential, especially in languages with complex morphology. For example, a rule can recognize transitions between uppercase and lowercase characters in camelcase words, or detect boundaries between Latin and non-Latin scripts. \n",
        "\n",
        "- **Special Character Processing:** Tokenizers may need rules to manege special characters like hashtags, mentions, or URLs, particularly when processing social media text. For instance, **@username** or **#hashtags** can be treated as single tokens to preserve their semantic meaning. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Advantages of Rule-Based Tokenization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Simplicity and Transparency:** Rule-based tokenization is straightforward to understand and implement, especially for well-defined languages. It allows developers to easily see how text is being processed and adjusted.\n",
        "\n",
        "- **Customizability:** This approach is highly customizable, enabling the creation of rules tailored to the specific requirements of a language or domain. For instance, a rule-based tokenizer can be adapted to handle the unique structure of legal texts or medical records.\n",
        "\n",
        "- **Efficiency for Simple Text:** Rule-based methods are often computationally efficient, as they do not require model training and can be directly applied to text based on the defined rules."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#####  **Challenges of Rule-Based Tokenization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Ambiguity:** One of the primary challenges of rule-based tokenization is handling ambiguous cases. For example, a period could signify the end of a sentence or be part of an abbreviation. Distinguishing between these uses often requires additional context that is difficult to capture with static rules.\n",
        "\n",
        "- **Scalability:** As text complexity increases, the number of required rules grows, making the system harder to maintain and extend. This can become problematic when handling diverse input types or multilingual data.\n",
        "\n",
        "- **Brittleness:** Rule-based systems can be brittle, breaking when encountering unexpected text formats or new language phenomena that are not covered by existing rules. Frequent updates may be needed to address these new cases.\n",
        "\n",
        "- **Language Dependency:** The rules must be tailored to each language, making it challenging to adapt a tokenizer designed for one language to another with different grammar, punctuation, or script."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **What is Machine Learning-Based Tokenization?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Machine learning-based tokenization uses statistical models and algorithms to determine the most appropriate way to split text into tokens. Unlike rule-based tokenization, which relies on predefined patterns, this approach learns from a training dataset to make tokenization decisions. The learning process enables the model to generalize from the examples it has seen and handle variations in text that may not be explicitly covered by rules. Popular methods include supervised learning models, probabilistic models, and neural network-based tokenization techniques."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Techniques in Machine Learning-Based Tokenization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Machine learning-based tokenization encompasses a variety of techniques, ranging from simple statistical models to advanced neural network architectures:\n",
        "\n",
        "- **Supervised Learning Models:**\n",
        "\n",
        "- Supervised models require a labeled training dataset where text is annotated with the correct token boundaries. The model learns to predict these boundaries for new, unseen text.\n",
        "\n",
        "\n",
        "- Common models include Conditional Random Fields (CRFs), which are effective in identifying token boundaries based on features such as word patterns, character n-grams, or contextual information.\n",
        "\n",
        "\n",
        "- **Probabilistic Models:**\n",
        "\n",
        "- Probabilistic approaches like Hidden Markov Models (HMMs) learn the likelihood of transitions between characters or words, making them effective for segmenting languages where word boundaries are not explicit (e.g., Chinese, Thai).\n",
        "\n",
        "\n",
        "- These models predict the sequence of labels (e.g., \"start of word\" or \"inside word\") that best matches the input text.\n",
        "\n",
        "\n",
        "- **Neural Network-Based Tokenization:**\n",
        "\n",
        "- Recent advances use deep learning models such as Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM) networks, and Transformers for tokenization.\n",
        "\n",
        "\n",
        "- Transformers, like those used in models such as BERT (Bidirectional Encoder Representations from Transformers), perform subword tokenization using methods like WordPiece or Byte-Pair Encoding (BPE).\n",
        "\n",
        "\n",
        "- These models tokenize text by learning to split words into smaller subwords or characters, thus handling rare words and out-of-vocabulary terms more effectively.\n",
        "\n",
        "\n",
        "- **Unsupervised Tokenization:**\n",
        "\n",
        "- In cases where labeled data is scarce, unsupervised methods such as BPE and SentencePiece break down text based on frequency statistics.\n",
        "\n",
        "\n",
        "- These methods iteratively merge the most frequent character pairs or subword units, creating a vocabulary that captures common word fragments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Advantages of Machine Learning-Based Tokenization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Flexibility and Adaptability:** Machine learning models can adapt to the text patterns of different languages and domains without the need for extensive manual rule crafting. This allows the model to generalize from training data and handle diverse text forms, such as slang, idioms, and new vocabulary.\n",
        "\n",
        "- **Handling Ambiguous Cases:** By learning from a large corpus, these models are better equipped to resolve ambiguous cases in tokenization, such as distinguishing between abbreviations and sentence boundaries.\n",
        "\n",
        "- **Robustness with Subwords:** Methods like BPE and WordPiece help in managing rare words and spelling variations by breaking words into smaller components. This is especially valuable for languages with rich morphology and compound words.\n",
        "\n",
        "- **Scalability:** Machine learning-based methods are scalable, making them suitable for large-scale applications like search engines, digital assistants, and large language models. They can process vast amounts of text and adjust their tokenization strategies as new data is introduced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Challenges of Machine Learning-Based Tokenization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Data Dependency:** These models require a significant amount of labeled data for training, especially when using supervised learning approaches. Acquiring and annotating this data can be costly and time-consuming.\n",
        "\n",
        "- **Computational Resources:** Training machine learning models for tokenization, particularly deep learning models like Transformers, can be resource-intensive, requiring substantial computational power and memory.\n",
        "\n",
        "- **Complexity:** Implementing and fine-tuning machine learning models for tokenization is more complex than designing rule-based systems. This complexity may not always be justified for simpler tokenization tasks where rules can suffice.\n",
        "\n",
        "- **Interpretability:** Machine learning models, especially neural networks, often operate as \"black boxes,\" making it difficult to understand how tokenization decisions are made. This lack of transparency can be a drawback when precise control over tokenization is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Comparison of Rule-Based & ML-Based Tokenization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Rule-based and machine learning-based tokenization are two fundamentally different approaches to breaking down text into tokens in Natural Language Processing (NLP). Each method has its own strengths and weaknesses, which make them suitable for different types of text processing tasks.\n",
        "\n",
        "\n",
        "Rule-based tokenization relies on predefined patterns and rules to split text. These rules might involve splitting text at whitespaces, handling punctuation, or using regular expressions to match specific patterns. This method is highly transparent and interpretable, allowing developers to understand precisely how tokenization decisions are being made. The simplicity of rule-based tokenization makes it easy to implement and maintain for specific, well-defined text forms, such as legal or medical documents, where language patterns are predictable. Rule-based methods excel in situations where precision is critical, such as tokenizing formal text where the structure is consistent.\n",
        "\n",
        "\n",
        "However, rule-based tokenization struggles with ambiguity and scalability. For instance, it may have difficulty distinguishing between periods used as sentence terminators versus those in abbreviations without additional context. As the complexity of language increases, so too does the number of rules needed, making the system harder to maintain. Additionally, adapting rule-based tokenization for different languages or domains requires extensive manual adjustments, limiting its flexibility.\n",
        "\n",
        "\n",
        "Machine learning-based tokenization, on the other hand, uses statistical models or neural networks to learn tokenization patterns directly from data. This approach does not rely on manually crafted rules but instead leverages training data to understand how text is typically segmented. It can adapt to new words, slang, and diverse sentence structures without requiring manual intervention. Methods like subword tokenization, as seen in models like BERT with WordPiece or Byte-Pair Encoding (BPE), are particularly effective in handling out-of-vocabulary words and rare terms, making them suitable for a wide range of applications, including language translation and large-scale NLP systems.\n",
        "\n",
        "\n",
        "This adaptability allows machine learning-based tokenizers to handle ambiguity more effectively than rule-based approaches. For example, they can learn from context to distinguish between abbreviations and sentence boundaries. Additionally, they scale well for large and varied corpora, making them ideal for use in search engines, chatbots, and other applications that process diverse user inputs.\n",
        "\n",
        "\n",
        "However, machine learning-based tokenization comes with its own challenges. It requires a large amount of labeled training data, which can be difficult and costly to obtain. The models themselves can be complex to train, tune, and implement, often necessitating significant computational resources, especially for deep learning-based tokenizers. Moreover, these models can act as \"black boxes,\" making it difficult to understand how certain tokenization decisions are made, which can be a drawback when transparency is required.\n",
        "\n",
        "\n",
        "In terms of application, rule-based tokenization is best suited for scenarios where language is consistent and formal, and where there is a need for simple, low-complexity solutions. It is a preferred choice when computational resources are limited or when interpretability is a priority. On the other hand, machine learning-based tokenization is the method of choice for modern NLP tasks, especially when dealing with diverse and unpredictable language inputs, large datasets, and applications where adaptability is crucial. This makes it particularly valuable for cutting-edge NLP models and dynamic environments where the language used is constantly evolving.\n",
        "\n",
        "\n",
        "Ultimately, the decision between using rule-based or machine learning-based tokenization depends on the specific requirements of a project. While rule-based tokenization offers precision and simplicity, machine learning-based tokenization provides the flexibility and robustness needed for more complex and large-scale applications. In many cases, a hybrid approach that combines the control of rules with the adaptability of machine learning can offer the best of both worlds, leading to more accurate and reliable tokenization in diverse contexts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **When to Use Rule-Based Tokenization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Rule-based tokenization is advantageous in situations where the language patterns are well-defined, predictable, and relatively simple. Here are specific conditions where rule-based tokenization is preferable:\n",
        "\n",
        "- **Highly Structured or Formal Texts:**\n",
        "\n",
        "Ideal for processing legal documents, medical records, or technical specifications, where the language is formal and follows a consistent structure. Rules can be tailored to handle specific patterns like citations, legal terminologies, or scientific abbreviations.\n",
        "\n",
        "\n",
        "For instance, if tokenizing legal clauses or medical terms, the structure is often predictable, making it easier to define rules that accurately segment the text.\n",
        "\n",
        "\n",
        "- **Limited Resources:**\n",
        "\n",
        "\n",
        "\n",
        "If computational power or memory is limited, rule-based tokenization is a better choice because it is less resource-intensive than machine learning models. It does not require the computational overhead of training and inference associated with ML-based tokenizers.\n",
        "\n",
        "\n",
        "For example, lightweight applications running on devices with minimal processing power, like embedded systems or simple web-based applications, benefit from the simplicity of rule-based tokenization.\n",
        "\n",
        "\n",
        "- **Need for Transparency and Interpretability:**\n",
        "\n",
        "When it is important to understand and explain how text is being tokenized, rule-based methods are preferable. They offer complete transparency because the rules are explicitly defined.\n",
        "\n",
        "\n",
        "This is useful in regulated industries or environments where understanding the processing logic is crucial for compliance, such as in healthcare or finance.\n",
        "\n",
        "\n",
        "- **Consistent Input Text:**\n",
        "\n",
        "\n",
        "If the text being processed is relatively uniform (e.g., fixed-format input like forms, surveys, or controlled user inputs), rule-based methods work effectively without needing complex adjustments.\n",
        "\n",
        "\n",
        "For example, in a chatbot that only receives inputs in a formal questionnaire style, rule-based tokenization can be set up quickly and reliably."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **When to Use ML-Based Tokenization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Machine learning-based tokenization shines in scenarios where language is diverse, constantly evolving, and harder to define with static rules. Here are conditions where machine learning-based tokenization is more suitable:\n",
        "\n",
        "- **Handling Complex and Diverse Text:**\n",
        "\n",
        "Machine learning-based tokenization is ideal for processing text from social media, online forums, and other user-generated content where the language can be informal, unstructured, and contains a variety of slang, abbreviations, and new vocabulary.\n",
        "\n",
        "\n",
        "For example, a system that needs to analyze Twitter posts or chat logs benefits from ML-based tokenization's ability to adapt to the diversity in language use, including emojis, hashtags, and colloquial terms.\n",
        "\n",
        "\n",
        "- **Large and Varied Datasets:**\n",
        "\n",
        "When dealing with large corpora that include a wide range of topics, domains, or multiple languages, machine learning-based tokenization is better suited. It can learn from the variability in the training data and generalize to new inputs.\n",
        "\n",
        "\n",
        "This is crucial for modern NLP applications like language models (e.g., GPT, BERT) that need to process vast amounts of text from different sources.\n",
        "\n",
        "\n",
        "- **Ambiguous or Context-Dependent Text:**\n",
        "\n",
        "If the text has ambiguities that require context to resolve (e.g., distinguishing between abbreviations and sentence boundaries or understanding the role of punctuation in different contexts), machine learning-based methods excel. They learn these nuances through training.\n",
        "For instance, determining whether â€œU.S.â€ is an abbreviation or a sentence end is more effectively handled by a model that has learned from diverse examples.\n",
        "\n",
        "\n",
        "- **Need for Scalability and Continuous Improvement:**\n",
        "\n",
        "When the goal is to build a system that can scale to millions of documents and adapt over time as new data is introduced, machine learning-based tokenization is advantageous. Once trained, these models can be applied to new data without needing to define additional rules manually.\n",
        "\n",
        "\n",
        "This is especially important in applications like search engines or virtual assistants, where the text being processed constantly evolves and adapts to user behavior.\n",
        "\n",
        "\n",
        "- **Handling Morphologically Rich Languages:**\n",
        "\n",
        "For languages with complex word formation rules (e.g., Finnish, Turkish, or agglutinative languages), machine learning models are often better equipped to manage variations in word forms by breaking words into subwords or character sequences.\n",
        "\n",
        "\n",
        "Subword tokenization methods like Byte-Pair Encoding (BPE) or WordPiece allow models to efficiently tokenize words that have never been seen before by decomposing them into familiar subwords."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 2.2: **Whitespace Tokenization** <a name=\"Whitespace\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tokenizers in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.20.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tokenizers) (0.25.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2023.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
            "Requirement already satisfied: requests in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.7.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install tokenizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Import necessart libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "qySerCxwn9Xj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Step 1:** Create a tokenizer with a WordLevel model and configure it with a whitespace pre-tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Step 2:** Set up the pre-tokenizer to split input text based on whitespace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer.pre_tokenizer = Whitespace()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Step 3:** Define the trainer with special tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Step 5:** Train the tokenizer on the specified dataset (ner.txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer.train([file_path], trainer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Step 6:** Read the text from the file and tokenize each line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenized_data = []\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "        line = line.strip()\n",
        "        if line:  \n",
        "            output = tokenizer.encode(line)\n",
        "            tokenized_data.append({\n",
        "                \"original_text\": line,\n",
        "                \"tokens\": output.tokens,\n",
        "                \"token_ids\": output.ids\n",
        "            })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Step 7:** Defile output json path & Save the tokenized data as a JSON file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_json_path = \"D:\\\\UT\\\\Courses\\\\NLP\\\\2024-Fall\\\\NLP_Dr_Faili\\\\HWs\\\\HW1\\\\HDA\\\\Data\\\\Data_Out\\\\Q1_P2_2_whitespace_tokenized_data.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(output_json_path, 'w', encoding='utf-8') as json_file:\n",
        "    json.dump(tokenized_data, json_file, ensure_ascii=False, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Step 8:** Display a portion of the results for verification & Show the first 3 entries to verify the tokenizatoin \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Text: As we move further into the digital age, the landscape of marketing is evolving at a pace faster than ever before. Businesses are harnessing the power of artificial intelligence, data analytics, and personalized advertising to reach their target audiences. If you wish to learn more about the latest trends, visit https://www.digitalfuture2025.com.\n",
            "Tokens: ['As', 'we', 'move', 'further', 'into', 'the', 'digital', 'age', ',', 'the', 'landscape', 'of', 'marketing', 'is', 'evolving', 'at', 'a', 'pace', 'faster', 'than', 'ever', 'before', '.', 'Businesses', 'are', 'harnessing', 'the', 'power', 'of', 'artificial', 'intelligence', ',', 'data', 'analytics', ',', 'and', 'personalized', 'advertising', 'to', 'reach', 'their', 'target', 'audiences', '.', 'If', 'you', 'wish', 'to', 'learn', 'more', 'about', 'the', 'latest', 'trends', ',', 'visit', 'https', '://', 'www', '.', 'digitalfuture2025', '.', 'com', '.']\n",
            "Token IDs: [175, 138, 319, 274, 297, 9, 33, 213, 6, 9, 305, 12, 19, 35, 110, 8, 23, 334, 267, 134, 109, 67, 5, 177, 25, 115, 9, 342, 12, 221, 295, 6, 44, 217, 6, 43, 82, 53, 10, 46, 13, 393, 224, 5, 96, 48, 417, 10, 78, 21, 52, 9, 77, 400, 6, 87, 26, 11, 14, 5, 73, 5, 15, 5]\n",
            "--------------------------------------------------\n",
            "Original Text: One significant change is the integration of augmented reality (AR) in advertising campaigns. Brands like VRInnovations (contact: info@vrinnovations.com) are leading the charge, offering immersive experiences that let users \"try\" products virtually before making a purchase. This level of engagement is a game-changer. For collaborations, reach out to their team at +1-800-555-1234.\n",
            "Tokens: ['One', 'significant', 'change', 'is', 'the', 'integration', 'of', 'augmented', 'reality', '(', 'AR', ')', 'in', 'advertising', 'campaigns', '.', 'Brands', 'like', 'VRInnovations', '(', 'contact', ':', 'info', '@', 'vrinnovations', '.', 'com', ')', 'are', 'leading', 'the', 'charge', ',', 'offering', 'immersive', 'experiences', 'that', 'let', 'users', '\"', 'try', '\"', 'products', 'virtually', 'before', 'making', 'a', 'purchase', '.', 'This', 'level', 'of', 'engagement', 'is', 'a', 'game', '-', 'changer', '.', 'For', 'collaborations', ',', 'reach', 'out', 'to', 'their', 'team', 'at', '+', '1', '-', '800', '-', '555', '-', '1234', '.']\n",
            "Token IDs: [196, 381, 234, 35, 9, 294, 12, 225, 358, 17, 171, 27, 34, 53, 69, 5, 176, 36, 206, 17, 38, 20, 75, 16, 412, 5, 15, 27, 25, 306, 9, 236, 6, 326, 286, 265, 47, 307, 407, 61, 401, 61, 347, 411, 67, 313, 23, 352, 5, 204, 308, 12, 57, 35, 23, 275, 7, 235, 5, 30, 239, 6, 46, 81, 10, 13, 60, 8, 18, 24, 7, 166, 7, 28, 7, 62, 5]\n",
            "--------------------------------------------------\n",
            "Original Text: In a report published by TechAdvisors (visit them at http://www.techadvisors.net), experts highlighted the rise of programmatic advertising as the next big thing. \"By 2025, we expect 90% of online ads to be placed using automated algorithms,\" says John Martinez, chief data scientist at TechAdvisors. You can contact him directly at john.martinez@techadvisors.net or at his office number +44 20 7946 0958 for more information on their latest research.\n",
            "Tokens: ['In', 'a', 'report', 'published', 'by', 'TechAdvisors', '(', 'visit', 'them', 'at', 'http', '://', 'www', '.', 'techadvisors', '.', 'net', '),', 'experts', 'highlighted', 'the', 'rise', 'of', 'programmatic', 'advertising', 'as', 'the', 'next', 'big', 'thing', '.', '\"', 'By', '2025', ',', 'we', 'expect', '90', '%', 'of', 'online', 'ads', 'to', 'be', 'placed', 'using', 'automated', 'algorithms', ',\"', 'says', 'John', 'Martinez', ',', 'chief', 'data', 'scientist', 'at', 'TechAdvisors', '.', 'You', 'can', 'contact', 'him', 'directly', 'at', 'john', '.', 'martinez', '@', 'techadvisors', '.', 'net', 'or', 'at', 'his', 'office', 'number', '+', '44', '20', '7946', '0958', 'for', 'more', 'information', 'on', 'their', 'latest', 'research', '.']\n",
            "Token IDs: [63, 23, 365, 351, 68, 97, 17, 87, 86, 8, 41, 11, 14, 5, 133, 5, 128, 49, 111, 282, 9, 368, 12, 348, 53, 222, 9, 321, 232, 395, 5, 61, 178, 144, 6, 138, 263, 168, 89, 12, 329, 212, 10, 66, 340, 408, 227, 215, 140, 371, 188, 193, 6, 237, 44, 373, 8, 97, 5, 51, 37, 38, 283, 106, 8, 301, 5, 315, 16, 133, 5, 128, 22, 8, 284, 80, 325, 18, 154, 142, 165, 141, 40, 21, 120, 45, 13, 77, 85, 5]\n",
            "--------------------------------------------------\n",
            "\n",
            "Tokenized data has been saved to: D:\\UT\\Courses\\NLP\\2024-Fall\\NLP_Dr_Faili\\HWs\\HW1\\HDA\\Data\\Data_Out\\Q1_P2_2_whitespace_tokenized_data.json\n"
          ]
        }
      ],
      "source": [
        "for entry in tokenized_data[:3]:\n",
        "    print(\"Original Text:\", entry[\"original_text\"])\n",
        "    print(\"Tokens:\", entry[\"tokens\"])\n",
        "    print(\"Token IDs:\", entry[\"token_ids\"])\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "print(f\"\\nTokenized data has been saved to: {output_json_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Disadvantages of Using Whitespace tokenizatoin**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Lack of Contextual Understanding**\n",
        "Whitespace tokenization purely relies on spaces to delineate tokens. This approach does not account for the linguistic context in which words appear. For example:\n",
        "\n",
        "**Polysemy and Homonymy:** Words that have multiple meanings (e.g., \"bark\" as in a tree or a dog's sound) are treated the same regardless of their context, potentially leading to semantic confusion in downstream tasks like sentiment analysis or machine translation.\n",
        "\n",
        "\n",
        "**Compound Words:** In languages like German or Chinese, words can be combined to form compound words or phrases that carry unique meanings (e.g., \"FahrvergnÃ¼gen\" in German). Whitespace tokenization fails to recognize these as single entities.\n",
        "\n",
        "\n",
        "- **Handling of Punctuation and Special Characters**\n",
        "\n",
        "Whitespace tokenization does not distinguish between words and punctuation, treating punctuation marks as separate tokens. This can lead to several issues:\n",
        "\n",
        "**Tokenization Artifacts:** Sentences like \"Hello, world!\" would yield the tokens [\"Hello,\", \"world!\"], which may not reflect the intended meanings or relationships between tokens. In NLP tasks requiring semantic analysis, this may introduce noise.\n",
        "\n",
        "\n",
        "**Inconsistent Tokenization:** Variations in punctuation use can lead to inconsistent tokenization results, which can negatively impact model training and performance.\n",
        "\n",
        "\n",
        "- **Inability to Handle Variations in Input**\n",
        "\n",
        "Whitespace tokenization is sensitive to variations in input text:\n",
        "\n",
        "\n",
        "**Case Sensitivity:** The tokenizer may treat \"Apple\" and \"apple\" as distinct tokens unless preprocessing is applied. This inconsistency can affect tasks such as text classification or entity recognition.\n",
        "\n",
        "\n",
        "**Leading/Trailing Spaces:** If input text has irregular spacing, such as double spaces, leading spaces, or trailing spaces, the tokenizer can produce unexpected results or fail to tokenize the text correctly.\n",
        "\n",
        "\n",
        "- **Limited Ability to Handle Multi-Word Expressions**\n",
        "\n",
        "Natural languages often include idiomatic expressions or multi-word phrases (e.g., \"kick the bucket\"). Whitespace tokenization does not recognize these as single tokens:\n",
        "\n",
        "\n",
        "**Loss of Semantic Integrity:** Tokenizing phrases like \"kick the bucket\" into [\"kick\", \"the\", \"bucket\"] can lead to a loss of the phrase's idiomatic meaning, adversely affecting understanding in tasks such as sentiment analysis or conversational agents.\n",
        "\n",
        "\n",
        "- **Inefficient for Certain Languages**\n",
        "\n",
        "Whitespace tokenization can be particularly ineffective for languages that do not use spaces as word delimiters, such as:\n",
        "\n",
        "**Chinese and Japanese:** These languages use characters without spaces to separate words, making whitespace tokenization unsuitable without additional preprocessing techniques.\n",
        "\n",
        "\n",
        "**Agglutinative Languages:** Languages like Turkish or Finnish, where words can be formed by concatenating multiple morphemes, may lead to overly granular tokenization that fails to capture meaningful linguistic units.\n",
        "\n",
        "\n",
        "- **Poor Generalization Across Domains**\n",
        "\n",
        "Different domains may use unique terminologies or jargon. Whitespace tokenization lacks the adaptability to learn or incorporate these specific linguistic patterns:\n",
        "\n",
        "\n",
        "**Domain-Specific Vocabulary:** In technical fields like medicine or law, where specific terms are crucial for accurate representation, whitespace tokenization will treat these terms based solely on spacing, failing to recognize their significance or relationship to each other.\n",
        "\n",
        "\n",
        "- **Dependency on Clean Data**\n",
        "\n",
        "Whitespace tokenization assumes that the input text is clean and well-formed. In practice, text data often contains errors, such as typos, missing spaces, or inconsistent formatting:\n",
        "\n",
        "\n",
        "**Data Preprocessing Overhead:** Significant preprocessing may be necessary to clean the data, including correcting spacing issues and normalizing punctuation, which can introduce additional complexity to the text processing pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtteugyooJS7"
      },
      "source": [
        "### Part 3.1: **Levenshtein & Damerau-Levenshtein Distances** <a name=\"Levenshtein_DamerauLevenshtein_Distance\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Levenshtein Distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In information theory, linguistics, and computer science, the **Levenshtein Distance** is a string metric for measuring the difference between two sequences. The Levenshtein distance between two words is the minimum number of single-character edits (insertions, deletions, substituitions) required to change one word into the other. \n",
        "\n",
        "Levenshtein distance may also be referred to as **Edit Distance**, although that term may also denote a larger family of distance metric known collectively as edit distancec. It closely related to **Pairwise String Alignments**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Example**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For example, the Levenshtein distance between \"kitten\" and \"sitting\" is 3, since the following 3 edits change one into the other, and there is no way to do it with fewer than 3 edits:\n",
        "\n",
        "- **K**itten -> **S**itten (Substitution of 'S' for 'K')\n",
        "\n",
        "- Sitt**e**n -> Sitt**i**n (Substitution of 'i' for 'e')\n",
        "\n",
        "- Sittin -> Sittin**g** (insertion of 'g' at the end)\n",
        "\n",
        "- Uni**n**formed -> Uniformed (Deletion of 'n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Levenshtein distance has several simple upper and lower bounds. These include:\n",
        "\n",
        "- It is at least the absolute value of the difference of the sizes of the two strings.\n",
        "\n",
        "- It is at most the length of the longer string.\n",
        "\n",
        "- It is zero if and only if the strings are equal.\n",
        "\n",
        "- If the strings have the same size, the **Hamming distance** is an upper bound on the Levenshtein distance. The Hamming distance is the number of positions at which the corresponding symbols in the two strings are different.\n",
        "\n",
        "- The Levenshtein distance between two strings is no greater than the sum of their Levenshtein distances from a third string (triangle inequality)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In **approximate string matching**, the objective is to find matches for short strings in many longer texts, in situations where a small number of differences is to be expected. The short strings could come from a dictionary, for instance. Here, one of the strings is typically short, while the other is arbitrarily long. This has a wide range of applications, for instance, spell checkers, correction systems for optical character recognition, and software to assist natural-language translation based on translation memory.\n",
        "\n",
        "The Levenshtein distance can also be computed between two longer strings, but the cost to compute it, which is roughly proportional to the product of the two string lengths, makes this impractical. Thus, when used to aid in fuzzy string searching in applications such as record linkage, the compared strings are usually short to help improve speed of comparisons.\n",
        "\n",
        "In linguistics, the Levenshtein distance is used as a metric to quantify the linguistic distance, or how different two languages are from one another. It is related to mutual intelligibility: the higher the linguistic distance, the lower the mutual intelligibility, and the lower the linguistic distance, the higher the mutual intelligibility."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **The process step-by-step of Levenshtein Distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Step 1: Define the Problem**\n",
        "    Given two strings:\n",
        "        - String A (length = m)\n",
        "        - String B (length = n)\n",
        "    The goal is to calculate the Levenshtein distance between these two strings, which represents the smallest number of edits needed to transform A into B.\n",
        "\n",
        "\n",
        "- **Step 2: Create a Matrix**\n",
        "    - Initialize a Matrix\n",
        "        Create a matrix d of size (m + 1) x (n + 1)\n",
        "        Each cell d[i][j] will represent the Levenshtein distance between the first i characters of String A and the first j characters of String B.\n",
        "    - Matrix Dimensions\n",
        "        The matrix has dimensions (m + 1) x (n + 1) because we account for the empty string as a prefix for both strings.\n",
        "\n",
        "\n",
        "- **Step 3: Initialize the Base Cases**\n",
        "    - The first row and column of the matrix are initialized to represent the distance when one of the strings is empty:\n",
        "        - First Row Initialization:\n",
        "            The first row corresponds to the distance from the empty string to the first j characters of String B. This distance is simply the number of insertions required to form String B from the empty string.\n",
        "            - Set d[0][j] = j for all j in the range [0, n]\n",
        "        \n",
        "        - First Column Initialization \n",
        "            - The first column corresponds to the distance from the first i characters of String A to the empty string. This distance is the number of deletions required to reduce String A to an empty string.\n",
        "            - Set d[i][0] = i for all i in the range [0, m]\n",
        "\n",
        "\n",
        "- **Step 4: Fill the Matrix**\n",
        "    - The next step is to iterate through each character of both strings and fill in the matrix based on the following rules:\n",
        "        - Iterate Through Each Character\n",
        "            - For each character A[i-1] from String A and B[j-1] from String B, calculate the edit distance using the previous values in the matrix.\n",
        "        - Determine Cost\n",
        "            - If the characters A[i-1] and B[j-1] are the same, the cost is 0 (no edit is needed)\n",
        "            - If they are different, the cost is 1 (substitution is needed)\n",
        "        - Calculate Minimum Distance\n",
        "            - The value in cell d[i][j] is calculated\n",
        "                - This formula considers:\n",
        "                    - The distance if the character from String A is deleted.\n",
        "                    - The distance if a character is added to String A to match String B.\n",
        "                    - The distance if the characters are replaced.\n",
        "\n",
        "\n",
        "- **Step 5: Retrieve the Result**\n",
        "    - The final step is to retrieve the value from the bottom-right cell of the matrix, which gives the Levenshtein distance between the two strings.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Damerau-Levenshtein Distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In information theory and computer science, the Damerauâ€“Levenshtein distance (named after Frederick J. Damerau and Vladimir I. Levenshtein) is a string metric for measuring the edit distance between two sequences. Informally, the Damerauâ€“Levenshtein distance between two words is the minimum number of operations (consisting of insertions, deletions or substitutions of a single character, or transposition of two adjacent characters) required to change one word into the other.\n",
        "\n",
        "The Damerauâ€“Levenshtein distance differs from the classical Levenshtein distance by including transpositions among its allowable operations in addition to the three classical single-character edit operations (insertions, deletions and substitutions).\n",
        "\n",
        "Damerau stated that in an investigation of spelling errors for an information-retrieval system, more than 80% were a result of a single error of one of the four types. Damerau's paper considered only misspellings that could be corrected with at most one edit operation. While the original motivation was to measure distance between human misspellings to improve applications such as spell checkers, Damerauâ€“Levenshtein distance has also seen uses in biology to measure the variation between protein sequences.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Damerau-Levenshtein distance between \"kitten\" and \"sitting\" is 3, since the following 3 edits change one into the other, and there is no way to do it with fewer than 3 edits:\n",
        "\n",
        "- **K**itten -> **S**itten (Substitution of 'S' for 'K')\n",
        "\n",
        "- Sitt**e**n -> Sitt**i**n (Substitution of 'i' for 'e')\n",
        "\n",
        "- Sittin -> Sittin**g** (Insertion of 'g' at the end)\n",
        "\n",
        "- Cd**e**f -> C**f**ed (Transposition of 'e' and 'f') \n",
        "\n",
        "- **C**d -> Dc (Transposition of 'c' and 'd')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **The process step-by-step of Damerau-Levenshtein Distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Damerau-Levenshtein distance measures the minimum number of edit operations required to transform one string into another. The allowable operations are:\n",
        "\n",
        "- **Insertion:** Adding a character.\n",
        "\n",
        "- **Deletion:** Removing a character.\n",
        "\n",
        "- **Substitution:** Replacing one character with another.\n",
        "\n",
        "- **Transposition:** Swapping two adjacent characters.\n",
        "\n",
        "---\n",
        "- **Initialize the Strings**\n",
        "  - Let A be the first string and B be the second string. \n",
        "\n",
        "- **Create a Distance Matrix**\n",
        "  - Create a 2D matrix D with dimensions (len(A) + 1) Ã— (len(B) + 1)\n",
        "\n",
        "- **Initialize Base Cases**\n",
        "  - Fill in the first row (0 to len(B)) and the first column (0 to len(A)) of the matrix:\n",
        "    - D[i][0]=i (cost of deleting all characters from A)\n",
        "    - D[0][j]=j (cost of inserting all characters into A to form B)\n",
        "\n",
        "- **Iterate through Characters**\n",
        "  - Loop through each character in A and B:\n",
        "    - For each character A[i] and B[j], Compute:\n",
        "      - If A[i] = B[j]:\n",
        "        - Set D[i][j] = D[i-1][j-1] (no cost if characters are the same)\n",
        "      - If A[i] =! B[j]:\n",
        "        - Set D[i][j] = min(deletion, insertion, substitution):\n",
        "        - D[i-1][j]+1 (deletion)\n",
        "        - D[i][j-1]+1 (insertion)\n",
        "        - D[i-1][j-1]+1 (substitution)\n",
        "\n",
        "- **Check for Transposition**\n",
        "  - If i>1 and j>1:\n",
        "    - If A[i] = B[j-1] and A[i-1] = B[j]:\n",
        "      - Set D[i][j]=min(D[i][j], D[i-2][j-2]+1) (Cost for transposition)\n",
        "\n",
        "- **Fill the matrix**\n",
        "  - Continue filling the matrix using the rules from Steps 4 and 5 until all characters are processed.\n",
        "\n",
        "- **Retrieve the Result**\n",
        "  - The value in the bottom-right cell of the matrix D[len(A)][len(B)] gives the Damerau-Levenshtein distance between the two strings.\n",
        "\n",
        "- **Return the Distance**\n",
        "  - Return or output the computed distance as the final result.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 3.2: **Levenshtein & Damerau-Levenshtein Distances In Py** <a name=\"implemented_Distances\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Levenshtein Distance in Py**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Import Necassary library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Lvenshtein Function**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function calculates the **Levenshtein distance** between two strings, **s1** and **s2**, which represents the minimum number of single-character edits required to transform one string into the other. The three possible operations are **insertion**, **deletion**, and **substitution** of characters.\n",
        "\n",
        "**Parameters:**\n",
        "  - **s1 (str)**: The first input string. \n",
        "  - **S2 (str)**: The second input string. \n",
        "\n",
        "**Returns:**\n",
        "  - **int**: The Levenshtein distance between **s1** and **s2**, indicating the minimum edit operations required. \n",
        "\n",
        "- **Matrix Initialization**: \n",
        "  - A 2D array **dp** of size ((n+1) * (m+1)) is created, where **n** and **m** are the lengths of **s1** and **s2**, respectively.\n",
        "    \n",
        "    - The first row is initialized to represent the cost of converting an empty string to **s2** (insertions).\n",
        "    \n",
        "    - The first column is initialized to represent the cost of converting **s1** to an empty string (deletions).\n",
        "  \n",
        "- **Matrix Filling**: \n",
        "  - Using a nested loop, the matrix is filled based on the following rules:\n",
        "    - If characters match **(s1[i-1] == s2[j-1])**, the value is taken from **dp[i-1][j-1]** as no edit is needed.\n",
        "    - If characters do not match, the value is the minimum of:\n",
        "      - **dp[i-1][j] + 1** (deletion),\n",
        "      - **dp[i][j-1] + 1** (insertion),\n",
        "      - **dp[i-1][j-1] + 1** (substitution).\n",
        "\n",
        "- **Result**: \n",
        "  The Levenshtein distance is found in the cell **dp[n][m]**, which contains the minimum number of edits required to transform **s1** into **s2**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "def levenshtein_distance(s1, s2):\n",
        "\n",
        "    n, m = len(s1), len(s2)\n",
        "    \n",
        "    dp = np.zeros((n + 1, m + 1), dtype=int)\n",
        "    \n",
        "    for i in range(n + 1):\n",
        "        dp[i][0] = i  \n",
        "    for j in range(m + 1):\n",
        "        dp[0][j] = j  \n",
        "    \n",
        "    for i in range(1, n + 1):\n",
        "        for j in range(1, m + 1):\n",
        "            \n",
        "            if s1[i - 1] == s2[j - 1]:\n",
        "\n",
        "                dp[i][j] = dp[i - 1][j - 1]\n",
        "            \n",
        "            else:\n",
        "            \n",
        "                dp[i][j] = min(\n",
        "                    dp[i - 1][j] + 1,  \n",
        "                    dp[i][j - 1] + 1,  \n",
        "                    dp[i - 1][j - 1] + 1  \n",
        "                )\n",
        "    \n",
        "    return dp[n][m]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **List of word pairs to calculate the Levenshtein distance**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "word_pairs = [\n",
        "    (\"kitten\", \"sitting\"),\n",
        "    (\"saturday\", \"sunday\"),\n",
        "    (\"book\", \"back\"),\n",
        "    (\"algorithm\", \"logarithm\"),\n",
        "    (\"\", \"test\"),\n",
        "    (\"abc\", \"acb\")\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Compute and display the distance for each pair**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Levenshtein distance between 'kitten' and 'sitting' is 3\n",
            "Levenshtein distance between 'saturday' and 'sunday' is 3\n",
            "Levenshtein distance between 'book' and 'back' is 2\n",
            "Levenshtein distance between 'algorithm' and 'logarithm' is 3\n",
            "Levenshtein distance between '' and 'test' is 4\n",
            "Levenshtein distance between 'abc' and 'acb' is 2\n"
          ]
        }
      ],
      "source": [
        "for s1, s2 in word_pairs:\n",
        "   \n",
        "    distance = levenshtein_distance(s1, s2)\n",
        "   \n",
        "    print(f\"Levenshtein distance between '{s1}' and '{s2}' is {distance}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Why These Results??**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. **Levenshtein distance between 'kitten' and 'sitting' is 3**\n",
        "  \n",
        "   The distance is **3** because three edits are needed to change \"kitten\" into \"sitting\":\n",
        "   \n",
        "      1. **Substitute 'k' with 's'**:  \n",
        "         \"kitten\" -> \"sitten\"\n",
        "      \n",
        "      2. **Substitute 'e' with 'i'**:  \n",
        "         \"sitten\" -> \"sittin\"\n",
        "      \n",
        "      3. **Insert 'g'**:  \n",
        "         \"sittin\" -> \"sitting\"\n",
        "\n",
        "---\n",
        "\n",
        "2. **Levenshtein distance between 'saturday' and 'sunday' is 3**\n",
        "   \n",
        "   The distance is **3** because three deletions are required to transform \"saturday\" into \"sunday\":\n",
        "   \n",
        "      1. **Delete 'a'**: \n",
        "         \"saturday\" -> \"sturday\"\n",
        "   \n",
        "      2. **Delete 't'**:  \n",
        "         \"sturday\" -> \"surday\"\n",
        "   \n",
        "      3. **Delete 'r'**:  \n",
        "      \"surday\" -> \"sunday\"\n",
        "---\n",
        "\n",
        "3. **Levenshtein distance between 'book' and 'back' is 2**\n",
        "\n",
        "   The distance is **2** because two substitutions are needed to change \"book\" into \"back\":\n",
        "\n",
        "      1. **Substitute 'o' with 'a'**:  \n",
        "         \"book\" -> \"baok\"\n",
        "      \n",
        "      2. **Substitute 'o' with 'c'**:  \n",
        "         \"baok\" -> \"back\"\n",
        "\n",
        "---\n",
        "\n",
        "4. **Levenshtein distance between 'algorithm' and 'logarithm' is 3**\n",
        "\n",
        "   The distance is **3** because three operations are required to transform \"algorithm\" into \"logarithm\":\n",
        "   \n",
        "      1. **Delete 'a'**:  \n",
        "         \"algorithm\" -> \"lgorithm\"\n",
        "      \n",
        "      2. **Insert 'l'**:  \n",
        "         \"lgorithm\" -> \"logarithm\"\n",
        "      \n",
        "      3. **No other operations are needed** since the remaining characters match.\n",
        "\n",
        "---\n",
        "\n",
        "5. **Levenshtein distance between '' and 'test' is 4**\n",
        "\n",
        "   The distance is **4** because four insertions are needed to transform an empty string into \"test\":\n",
        "   \n",
        "      1. **Insert 't'**:  \n",
        "         \"\" -> \"t\"\n",
        "      \n",
        "      2. **Insert 'e'**:  \n",
        "         \"t\" -> \"te\"\n",
        "      \n",
        "      3. **Insert 's'**:  \n",
        "         \"te\" -> \"tes\"\n",
        "      \n",
        "      4. **Insert 't'**:  \n",
        "         \"tes\" â†’ \"test\"\n",
        "\n",
        "---\n",
        "\n",
        "6. **Levenshtein distance between 'abc' and 'acb' is 2**\n",
        "   The distance is **2** because two operations (substitutions) are needed to change \"abc\" into \"acb\":\n",
        "      1. **Substitute 'b' with 'c'**:  \n",
        "         \"abc\" -> \"acc\"\n",
        "      \n",
        "      2. **Substitute 'c' with 'b'**: \n",
        "         \"acc\" -> \"acb\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Damerau-Levenshtein Distance in Py**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Insertion**: Adding a character to the string.\n",
        "\n",
        "- **Deletion**: Removing a character from the string.\n",
        "\n",
        "- **Substitution**: Replacing one character with another.\n",
        "\n",
        "- **Transposition**: Swapping two adjacent characters.\n",
        "\n",
        "**Function Definition**\n",
        "\n",
        "The following Python function, **damerau_levenshtein_distance**, calculates the Damerau-Levenshtein distance between two input strings, **s1** and **s2**.\n",
        "\n",
        "**Function Details**\n",
        "\n",
        "- **Input**:\n",
        "  - **s1**: The first string.\n",
        "  - **s2**: The second string.\n",
        "\n",
        "- **Output**:\n",
        "  - Returns an integer representing the Damerau-Levenshtein distance between the two strings.\n",
        "\n",
        "\n",
        "1. **Matrix Initialization**: \n",
        "   - A 2D matrix **dp** is created, where **dp[i][j]** will hold the distance between the first **i** characters of **s1** and the first **j** characters of **s2**.\n",
        "   - The first row and first column of the matrix are initialized to represent the cost of converting an empty string to the other string.\n",
        "\n",
        "2. **Distance Calculation**:\n",
        "   - A nested loop iterates through each character of **s1** and **s2**. For each pair of characters, the function:\n",
        "     - Checks if they match. If they do, the cost remains the same as **dp[i-1][j-1]**.\n",
        "     - If they don't match, it calculates the minimum cost among deletion, insertion, and substitution.\n",
        "     - Additionally, it checks for transpositions (swapping of adjacent characters) to account for this operation.\n",
        "\n",
        "3. **Return Value**:\n",
        "   - The final Damerau-Levenshtein distance is found in the bottom-right cell of the matrix, **dp[n][m]**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "def damerau_levenshtein_distance(s1, s2):\n",
        "\n",
        "    n, m = len(s1), len(s2)\n",
        "    \n",
        "    dp = np.zeros((n + 1, m + 1), dtype=int)    \n",
        "\n",
        "    for i in range(n + 1):\n",
        "        dp[i][0] = i  \n",
        "    for j in range(m + 1):\n",
        "        dp[0][j] = j \n",
        "    \n",
        "    for i in range(1, n + 1):\n",
        "        for j in range(1, m + 1):\n",
        "            if s1[i - 1] == s2[j - 1]:\n",
        "\n",
        "                dp[i][j] = dp[i - 1][j - 1]\n",
        "            else:\n",
        "\n",
        "                dp[i][j] = min(\n",
        "                    dp[i - 1][j] + 1, \n",
        "                    dp[i][j - 1] + 1, \n",
        "                    dp[i - 1][j - 1] + 1  \n",
        "                )\n",
        "                \n",
        "            if i > 1 and j > 1 and s1[i - 1] == s2[j - 2] and s1[i - 2] == s2[j - 1]:\n",
        "                dp[i][j] = min(dp[i][j], dp[i - 2][j - 2] + 1)  \n",
        "\n",
        "    return dp[n][m]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Compute the Damerau-Levenshtein distance for each pair**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Damerau-Levenshtein distance between 'kitten' and 'sitting' is 3\n",
            "Damerau-Levenshtein distance between 'saturday' and 'sunday' is 3\n",
            "Damerau-Levenshtein distance between 'book' and 'back' is 2\n",
            "Damerau-Levenshtein distance between 'algorithm' and 'logarithm' is 3\n",
            "Damerau-Levenshtein distance between '' and 'test' is 4\n",
            "Damerau-Levenshtein distance between 'abc' and 'acb' is 1\n"
          ]
        }
      ],
      "source": [
        "for s1, s2 in word_pairs:\n",
        "   \n",
        "    distance = damerau_levenshtein_distance(s1, s2)\n",
        "   \n",
        "    print(f\"Damerau-Levenshtein distance between '{s1}' and '{s2}' is {distance}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Why These Results??**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. **Damerau-Levenshtein distance between 'kitten' and 'sitting' is 3**\n",
        "   - **Substitution**: 'k' is changed to 's' -> \"kitten\" becomes \"sitten\".\n",
        "   - **Substitution**: 'e' is changed to 'i' -> \"sitten\" becomes \"sittin\".\n",
        "   - **Insertion**: Add 'g' at the end -> \"sittin\" becomes \"sitting\".\n",
        "   - Thus, the distance is 3.\n",
        "---\n",
        "2. **Damerau-Levenshtein distance between 'saturday' and 'sunday' is 3**\n",
        "   - **Deletion**: Remove 'a' -> \"saturday\" becomes \"sturday\".\n",
        "   - **Deletion**: Remove 't' -> \"sturday\" becomes \"surday\".\n",
        "   - **Deletion**: Remove 'r' -> \"surday\" becomes \"sunday\".\n",
        "   - Thus, the distance is 3.\n",
        "---\n",
        "3. **Damerau-Levenshtein distance between 'book' and 'back' is 2**\n",
        "   - **Substitution**: 'o' is changed to 'a' -> \"book\" becomes \"baok\".\n",
        "   - **Substitution**: 'o' is changed to 'c' -> \"baok\" becomes \"back\".\n",
        "   - Thus, the distance is 2.\n",
        "---\n",
        "4. **Damerau-Levenshtein distance between 'algorithm' and 'logarithm' is 3**\n",
        "   - **Deletion**: Remove 'a' at the start -> \"algorithm\" becomes \"lgorithm\".\n",
        "   - **Insertion**: Add 'l' at the beginning -> \"lgorithm\" becomes \"logarithm\".\n",
        "   - **Transposition**: Swap 'a' and 'l' (but this adjustment was counted as a separate step) -> \"lgorithm\" aligns with \"logarithm\".\n",
        "   - Thus, the distance is 3.\n",
        "---\n",
        "5. **Damerau-Levenshtein distance between '' and 'test' is 4**\n",
        "   - **Insertion**: Add 't' -> \"\" becomes \"t\".\n",
        "   - **Insertion**: Add 'e' -> \"t\" becomes \"te\".\n",
        "   - **Insertion**: Add 's' -> \"te\" becomes \"tes\".\n",
        "   - **Insertion**: Add 't' -> \"tes\" becomes \"test\".\n",
        "   - Thus, the distance is 4.\n",
        "---\n",
        "6. **Damerau-Levenshtein distance between 'abc' and 'acb' is 1**\n",
        "   - **Transposition**: Swap 'b' and 'c' -> \"abc\" becomes \"acb\".\n",
        "   - Thus, the distance is 1, as only one transposition is needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Difference in Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Levenshtein vs. Damerau-Levenshtein for 'abc' and 'acb'**\n",
        "\n",
        "- **Levenshtein distance**: **2**\n",
        "- **Damerau-Levenshtein distance**: **1**\n",
        "\n",
        "**Whyyy???!**:  \n",
        "- With **Levenshtein**, transforming \"abc\" into \"acb\" requires two substitutions:  \n",
        "  - **Substitute 'b' with 'c'**:  \n",
        "    \"abc\" -> \"acc\"  \n",
        "  \n",
        "  - **Substitute 'c' with 'b'**:  \n",
        "    \"acc\" -> \"acb\"  \n",
        "  - Total edits: **2**\n",
        "\n",
        "- With **Damerau-Levenshtein**, the same transformation can be achieved with a single **transposition** of 'b' and 'c':  \n",
        "  \n",
        "  - **Transposition**: Swap 'b' and 'c' directly:  \n",
        "    \"abc\" -> \"acb\"  \n",
        "  \n",
        "  - Total edits: **1**\n",
        "\n",
        "**Difference**:  \n",
        "- **Damerau-Levenshtein distance** is **1** due to its ability to account for the transposition, whereas **Levenshtein** counts it as two separate substitutions, resulting in a distance of **2**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W26Ui-KYUm2"
      },
      "source": [
        "\n",
        "## **Chapter 2: N-Gram Language Models** <a name=\"Chapter-2\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InJwAZtomudc"
      },
      "source": [
        "### CH2-Data: **About Dataset** <a name=\"CH2-data\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Ferdowsi:**\n",
        "  \n",
        "    - **Ø®Ø¯Ø§ÙˆÙ†Ø¯ Ú©ÛŒÙˆØ§Ù† Ùˆ Ú¯Ø±Ø¯Ø§Ù† Ø³Ù¾Ù‡Ø±**        \n",
        "    \n",
        "    - **ÙØ±ÙˆØ²Ù†Ø¯Ù‡ Ù…Ø§Ù‡ Ùˆ Ù†Ø§Ù‡ÛŒØ¯ Ùˆ Ù…Ù‡Ø±**\n",
        "\n",
        "- **Hafez**\n",
        "\n",
        "    - **Ù…Ø¨ÙŠÙ† Ø¨Ù‡ Ø³ÙŠØ¨ Ø²Ù†Ø®Ø¯Ø§Ù† Ú©Ù‡ Ú†Ø§Ù‡ Ø¯Ø± Ø±Ø§Ù‡ Ø§Ø³Øª**    \n",
        "    \n",
        "    -  **Ú©Ø¬Ø§ Ù‡Ù…ÛŒâ€ŒØ±ÙˆÛŒ Ø§ÛŒ Ø¯Ù„ Ø¨Ø¯ÛŒÙ† Ø´ØªØ§Ø¨ Ú©Ø¬Ø§**\n",
        "\n",
        "- **Modern Poet**\n",
        "    \n",
        "    - **Ù…Ù† Ù†Ø¯Ø§Ù†Ù… Ø¨Ø§ Ú©Ù‡ Ú¯ÙˆÛŒÙ… Ø´Ø±Ø­ Ø¯Ø±Ø¯ Ù‚ØµÙ‡ ÛŒ Ø±Ù†Ú¯ Ù¾Ø±ÛŒØ¯Ù‡ ØŒ Ø®ÙˆÙ† Ø³Ø±Ø¯ ØŸ Ù‡Ø± Ú©Ù‡ Ø¨Ø§ Ù…Ù† Ù‡Ù…Ø±Ù‡ Ùˆ Ù¾ÛŒÙ…Ø§Ù†Ù‡ Ø´Ø¯ Ø¹Ø§Ù‚Ø¨Øª Ø´ÛŒØ¯Ø§ Ø¯Ù„ Ùˆ Ø¯ÛŒÙˆØ§Ù†Ù‡ Ø´Ø¯**\n",
        "\n",
        "---\n",
        "- **After Normalization**\n",
        "\n",
        "    - **Ferdowsi**\n",
        "        - **Ø®Ø¯Ø§ÙˆÙ†Ø¯ Ú©ÛŒÙˆØ§Ù† Ùˆ Ú¯Ø±Ø¯Ø§Ù† Ø³Ù¾Ù‡Ø±** (ÙØ§ØµÙ„Ù‡)**ÙØ±ÙˆØ²Ù†Ø¯Ù‡ Ù…Ø§Ù‡ Ùˆ Ù†Ø§Ù‡ÛŒØ¯ Ùˆ Ù…Ù‡Ø±**\n",
        "\n",
        "    - **Hafez**\n",
        "        - **Ù…Ø¨ÛŒÙ† Ø¨Ù‡ Ø³ÛŒØ¨ Ø²Ù†Ø®Ø¯Ø§Ù† Ú©Ù‡ Ø¬Ø§Ù„Ù‡ Ø¯Ø± Ø±Ø§Ù‡ Ø§Ø³Øª**(ÙØ§ØµÙ„Ù‡)**Ú©Ø¬Ø§ Ù‡Ù…ÛŒâ€ŒØ±ÙˆÛŒ Ø§ÛŒ Ø¯Ù„ Ø¨Ø¯ÛŒÙ† Ø´ØªØ§Ø¨ Ú©Ø¬Ø§**\n",
        "    - **Modern Poet**\n",
        "        - **Ù…Ù† Ù†Ø¯Ø§Ù†Ù… Ø¨Ø§ Ú©Ù‡ Ú¯ÙˆÛŒÙ… Ø´Ø±Ø­ Ø¯Ø±Ø¯ Ù‚ØµÙ‡ ÛŒ Ø±Ù†Ú¯ Ù¾Ø±ÛŒØ¯Ù‡ ØŒ Ø®ÙˆÙ† Ø³Ø±Ø¯ ØŸ Ù‡Ø± Ú©Ù‡ Ø¨Ø§ Ù…Ù† Ù‡Ù…Ø±Ù‡ Ùˆ Ù¾ÛŒÙ…Ø§Ù†Ù‡ Ø´Ø¯ Ø¹Ø§Ù‚Ø¨Øª Ø´ÛŒØ¯Ø§ Ø¯Ù„ Ùˆ Ø¯ÛŒÙˆØ§Ù†Ù‡ Ø´Ø¯**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 1.1: **WordPiece** <a name=\"Wordpiece_Tokenizer\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Wordpiece** is a subword tokenization algorithm closely related to **Pyte Pair Encoding (BPE)**. \n",
        "   \n",
        "    - Developed by **Google**.\n",
        "    \n",
        "    - It was initially used for Japanese and Korean voice search, and later became a crucial component in models like:\n",
        "        \n",
        "        - **BERT**\n",
        "        \n",
        "        - **DistilBERT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **How Wordpiece Relates to BPE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wordpiece and BPE share the same fundamental concept: iteratively merging frequent pairs of characters or subwords to create a vocabulary of subword units.\n",
        "\n",
        "However, WordPiece introduce a  modification in how it selects pairs merge. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **WordPiece Algorithm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. **Initialization**\n",
        "    \n",
        "    - **Process**\n",
        "        \n",
        "        1. Start with a vocabulary of individual characters from the training corpus. \n",
        "\n",
        "        2. Add special tokens:\n",
        "\n",
        "            - **[UNK]** for unknown tokens.\n",
        "\n",
        "            - **##prefix** for subwords that don't start a word.\n",
        "    \n",
        "    - **Rationale**\n",
        "\n",
        "        1. Character-level initialization ensures coverage of all possible subwords.\n",
        "\n",
        "        2. Special tokens help in handling unseen words and maintaining word boundary information.\n",
        "\n",
        "2. **Tokenizatoin of Training data**\n",
        "\n",
        "    - **Process**\n",
        "\n",
        "        1. Split the training corpus into words.\n",
        "\n",
        "        2. For each word, create all possible subword combinations.\n",
        "    \n",
        "    - **Rationale**\n",
        "\n",
        "        This step creates the initial pool of potential subwords to consider for the vocabulary.\n",
        "\n",
        "3. **Calculating Token Frequencies**\n",
        "\n",
        "    - **Process**\n",
        "\n",
        "        1. Count the frequency of each subword in the training data.\n",
        "\n",
        "        2. Keep track of which subwords appear at the start of words vs. in the middle/end.\n",
        "    \n",
        "    - **Ratoinale**\n",
        "\n",
        "        1. Frequency information is crucial for the scoring step.\n",
        "\n",
        "        2. Distinguishing between word-initial and non-initial subwords helps maintain word structure information.\n",
        "\n",
        "4. **Iterative Merging**\n",
        "    \n",
        "    - This is the core of the algorithm, repeated until the desired vocabulary size is reached or the highest score falls below a threshold.\n",
        "    \n",
        "    - 4.1 **Score Calculation**\n",
        "        \n",
        "        - **Formula**\n",
        "            $$ \\text{score}(A,B) = \\frac{\\text{freq}(A,B)}{\\text{freq}(A) \\times \\text{freq}(B)} $$\n",
        "\n",
        "        \n",
        "        - **Where:**\n",
        "\n",
        "            - freq(AB) is the frequency of the combined token.\n",
        "\n",
        "            - len(vocab) is the current vocabulary size.\n",
        "\n",
        "            - freq(A) and freq(B) are the individual frequencies of A and B.\n",
        "    \n",
        "        - **Process**\n",
        "            \n",
        "            - Calculate this score for every possible pair of tokens in the current vocabulary.\n",
        "        \n",
        "        - **Rationale**\n",
        "            \n",
        "            1. This score approximates the likelihood improvement of the training data if this merge is performed.\n",
        "            \n",
        "            2. Multiplying by len(vocab) gives a slight preference to longer subword units as the vocabulary grows.\n",
        "    \n",
        "    - 4.2 **Pair Selection**\n",
        "\n",
        "        - **Process**\n",
        "\n",
        "            - Select the pair with the highest score.\n",
        "        \n",
        "        - **Rationale**\n",
        "\n",
        "            - This pair represents the merge that would most improve the modelâ€™s ability to compress the training data.\n",
        "    \n",
        "    - 4.3 **Merging**\n",
        "\n",
        "        - **Process**\n",
        "\n",
        "            1. Add the merged token to the vocabulary.\n",
        "\n",
        "            2. If itâ€™s not a word-initial subword, add it with the ## prefix.\n",
        "\n",
        "            3. Update the tokenization of the training data to use this new token where applicable.\n",
        "\n",
        "        - **Rationale**\n",
        "\n",
        "            1. This step gradually builds up the vocabulary with the most useful subword units.\n",
        "\n",
        "            2. The ## prefix helps maintain information about word structure.\n",
        "\n",
        "    - 4.4 **Frequency Update**\n",
        "\n",
        "        - **Process**\n",
        "\n",
        "            1. Update the frequencies of all affected tokens.\n",
        "\n",
        "            2. This includes the new merged token and any tokens that contained the merged pair.\n",
        "        \n",
        "        - **Rationale**\n",
        "\n",
        "            - Keeping accurate frequency counts is crucial for subsequent scoring rounds.\n",
        "\n",
        "5. **Stopping Criterion**\n",
        "\n",
        "    - **Options**\n",
        "\n",
        "        1. Reach a predefined vocabulary size.\n",
        "\n",
        "        2. Continue until the highest merge score falls below a certain threshold.\n",
        "    \n",
        "    - **Rationale**\n",
        "\n",
        "        1. A fixed vocabulary size ensures predictable memory usage and computation time in downstream models.\n",
        "\n",
        "        2. A score threshold can help ensure that only meaningful merges are performed.\n",
        "\n",
        "6. **Final Vocabulary Construction**\n",
        "\n",
        "    - **Process**\n",
        "\n",
        "        1. Once stopping criterion is met, finalize the vocabulary.\n",
        "\n",
        "        2. Ensure all tokens are unique and properly formatted (with ## for non-initial subwords).\n",
        "    \n",
        "    - **Rationale**\n",
        "\n",
        "        - The final vocabulary should be clean and ready for use in tokenization tasks.\n",
        "\n",
        "7. **Tokenization Algorithm**\n",
        "\n",
        "    - Once the WordPiece vocabulary is constructed, tokenization of new text follows these steps:\n",
        "\n",
        "        1. Split the input text into words.\n",
        "\n",
        "        2. For each word:\n",
        "\n",
        "            A. Try to match the longest subword from the vocabulary at the start of the word.\n",
        "\n",
        "            B. If a match is found, add it to the output and repeat from the next character.\n",
        "\n",
        "            C. If no match is found, add [UNK] token and move to the next character.\n",
        "\n",
        "            D. For matches after the first character, use the ## version of the subword.\n",
        "    \n",
        "    - **Rationale**\n",
        "\n",
        "        1. This greedy longest-match approach ensures consistent tokenization.\n",
        "\n",
        "        2. It balances the use of larger subword units where possible with the ability to fall back to smaller units when needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 1.2: **Models Using WordPiece** <a name=\"Models\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**WordPiece Tokenization** is a **subword tokenization algorithm** originally developed for use in the **BERT (Bidirectional Encoder Representations from Transformers) model by Google**.\n",
        "\n",
        "- **Applications in BERT**\n",
        "\n",
        "    - 1. **Vocabulary Efficiency:** By using subwords, BERT reduces the size of the vocabulary needed to handle the vast variety of words in natural language, allowing it to work effectively with smaller datasets.\n",
        "\n",
        "    - 2. **Handling OOV Words:** Instead of failing to recognize an unknown word, WordPiece can decompose it into known subwords, enabling the model to still derive meaning from the context in which the OOV word appears.\n",
        "\n",
        "    - 3. **Improved Performance:** The subword approach allows BERT to capture semantic relationships and nuances better than traditional tokenization methods, as it can represent morphological variations of words.\n",
        "\n",
        "- **Models Using WordPiece**\n",
        "\n",
        "    - **ALBERT (A Lite BERT):** A samller & faster variant of BERT.\n",
        "\n",
        "    - **DistilBERT:** A distilled version of BERT, optimized for efficiency.\n",
        "\n",
        "    - **Electra**\n",
        "\n",
        "    - **XLNet:** A model that combined the advantages of BERT with a generalized autoregressive pretraining. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 1.3: **Comparision with BPE** <a name=\"BPE\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **WordPiece Tokenization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Merging Strategy:** WordPiece selects the most common subword tokens based on their frequency in the training corpus. This process ensures that common words or subword forms are prioritized, making it easier for the model to understand contextual meanings.\n",
        "\n",
        "- **Contextual Awareness:** The tokenization process is designed to capture subword-level semantics, which can help in languages with rich morphology, where different forms of a word may carry different meanings.\n",
        "\n",
        "- **Training Dependency:** WordPiece requires a substantial amount of training data to create a comprehensive vocabulary. This makes it particularly effective in scenarios where extensive text data is available.\n",
        "\n",
        "- **Performance:** Models using WordPiece, like BERT, often outperform those using simpler tokenization techniques, especially on tasks requiring deeper contextual understanding, such as sentiment analysis, named entity recognition, and question answering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Byte Pair Encoding (BPE)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Merging Pairs:** BPE works by identifying the most frequently occurring pairs of characters in a text and merging them iteratively. This continues until a specified vocabulary size is reached, leading to a vocabulary that reflects the most common patterns.\n",
        "\n",
        "- **Simplicity:** The algorithm is straightforward to implement, which makes it appealing for many NLP applications. It does not require extensive language-specific adjustments, allowing it to be easily applied to various languages.\n",
        "\n",
        "- **Flexibility:** While BPE can adapt to different languages, its tokenization may lead to less semantically meaningful subwords, especially in languages with complex morphology, where meaning might be lost.\n",
        "\n",
        "- **Performance:** BPE has shown to be effective in general-purpose language models, such as GPT-2 and RoBERTa, but may not capture the nuanced semantic relationships as effectively as WordPiece does in tasks requiring high levels of contextual understanding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 2.1: **Train Wordpiece Tokenizer on Ferdowsi** <a name=\"Ferdowsi_Tokenizatoin\"></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os \n",
        "import re\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import codecs\n",
        "from itertools import product\n",
        "from __future__ import unicode_literals\n",
        "from typing import Dict, List, Union\n",
        "from collections import Counter\n",
        "import tqdm\n",
        "import tokenizer\n",
        "import nltk\n",
        "from tokenizers import Tokenizer, models, trainers, BertWordPieceTokenizer\n",
        "from hazm import *\n",
        "from hazm import Normalizer\n",
        "from PersianG2p import Persian_g2p_converter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "Ferdowsi_Path = rXXX\n",
        "Normalized_ferdowsi_path = rXXX\n",
        "tokenizer_model_path =  rXXX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Information extraction from Data & Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_and_analyze_dataset(file_path: str) -> Dict[str, Union[int, List[str], Dict[str, Union[int, List[int]]]]]:\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "    lines = text.split('\\n')\n",
        "    num_lines = len(lines)\n",
        "    stanzas = text.split('\\n\\n')\n",
        "    num_stanzas = len(stanzas)\n",
        "    line_word_counts = []\n",
        "    max_words_in_line = 0\n",
        "    total_sentences = 0\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        words = line.split()\n",
        "        line_word_counts.append(len(words))\n",
        "        max_words_in_line = max(max_words_in_line, len(words))\n",
        "        total_sentences += len(re.findall(r'[Ø›.!ØŸ]', line))\n",
        "    num_chars = len(text)\n",
        "    preview_text = text[:1500] \n",
        "\n",
        "    return {\n",
        "        'num_lines': num_lines,\n",
        "        'num_stanzas': num_stanzas,\n",
        "        'num_chars': num_chars,\n",
        "        'preview_text': preview_text,\n",
        "        'line_word_counts': line_word_counts,\n",
        "        'max_words_in_line': max_words_in_line,\n",
        "        'total_sentences': total_sentences,\n",
        "        'full_text': text\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load and analyze the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of lines: 99219\n",
            "Number of characters: 2653849\n",
            "Maximum number of words in any line: 11\n"
          ]
        }
      ],
      "source": [
        "dataset_info = load_and_analyze_dataset(Ferdowsi_Path)\n",
        "print(f\"Number of lines: {dataset_info['num_lines']}\")\n",
        "print(f\"Number of characters: {dataset_info['num_chars']}\")\n",
        "print(f\"Maximum number of words in any line: {dataset_info['max_words_in_line']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preview of the text:\n",
            "|Ø¨Ù‡ Ù†Ø§Ù… Ø®Ø¯Ø§ÙˆÙ†Ø¯ Ø¬Ø§Ù† Ùˆ Ø®Ø±Ø¯\n",
            "|Ú©Ø²ÛŒÙ† Ø¨Ø±ØªØ± Ø§Ù†Ø¯ÛŒØ´Ù‡ Ø¨Ø±Ù†Ú¯Ø°Ø±Ø¯\n",
            "|Ø®Ø¯Ø§ÙˆÙ†Ø¯ Ù†Ø§Ù… Ùˆ Ø®Ø¯Ø§ÙˆÙ†Ø¯ Ø¬Ø§ÛŒ\n",
            "|Ø®Ø¯Ø§ÙˆÙ†Ø¯ Ø±ÙˆØ²ÛŒ Ø¯Ù‡ Ø±Ù‡Ù†Ù…Ø§ÛŒ\n",
            "|Ø®Ø¯Ø§ÙˆÙ†Ø¯ Ú©ÛŒÙˆØ§Ù† Ùˆ Ú¯Ø±Ø¯Ø§Ù† Ø³Ù¾Ù‡Ø±\n",
            "|ÙØ±ÙˆØ²Ù†Ø¯Ù‡ Ù…Ø§Ù‡ Ùˆ Ù†Ø§Ù‡ÛŒØ¯ Ùˆ Ù…Ù‡Ø±\n",
            "|Ø² Ù†Ø§Ù… Ùˆ Ù†Ø´Ø§Ù† Ùˆ Ú¯Ù…Ø§Ù† Ø¨Ø±ØªØ±Ø³Øª\n",
            "|Ù†Ú¯Ø§Ø±Ù†Ø¯Ù‡Ù” Ø¨Ø± Ø´Ø¯Ù‡ Ù¾ÛŒÚ©Ø±Ø³Øª\n",
            "|Ø¨Ù‡ Ø¨ÛŒÙ†Ù†Ø¯Ú¯Ø§Ù† Ø¢ÙØ±ÛŒÙ†Ù†Ø¯Ù‡ Ø±Ø§\n",
            "|Ù†Ø¨ÛŒÙ†ÛŒ Ù…Ø±Ù†Ø¬Ø§Ù† Ø¯Ùˆ Ø¨ÛŒÙ†Ù†Ø¯Ù‡ Ø±Ø§\n",
            "|Ù†ÛŒØ§Ø¨Ø¯ Ø¨Ø¯Ùˆ Ù†ÛŒØ² Ø§Ù†Ø¯ÛŒØ´Ù‡ Ø±Ø§Ù‡\n",
            "|Ú©Ù‡ Ø§Ùˆ Ø¨Ø±ØªØ± Ø§Ø² Ù†Ø§Ù… Ùˆ Ø§Ø² Ø¬Ø§ÛŒÚ¯Ø§Ù‡\n",
            "|Ø³Ø®Ù† Ù‡Ø± Ú†Ù‡ Ø²ÛŒÙ† Ú¯ÙˆÙ‡Ø±Ø§Ù† Ø¨Ú¯Ø°Ø±Ø¯\n",
            "|Ù†ÛŒØ§Ø¨Ø¯ Ø¨Ø¯Ùˆ Ø±Ø§Ù‡ Ø¬Ø§Ù† Ùˆ Ø®Ø±Ø¯\n",
            "|Ø®Ø±Ø¯ Ú¯Ø± Ø³Ø®Ù† Ø¨Ø±Ú¯Ø²ÛŒÙ†Ø¯ Ù‡Ù…ÛŒ\n",
            "|Ù‡Ù…Ø§Ù† Ø±Ø§ Ú¯Ø²ÛŒÙ†Ø¯ Ú©Ù‡ Ø¨ÛŒÙ†Ø¯ Ù‡Ù…ÛŒ\n",
            "|Ø³ØªÙˆØ¯Ù† Ù†Ø¯Ø§Ù†Ø¯ Ú©Ø³ Ø§Ùˆ Ø±Ø§ Ú†Ùˆ Ù‡Ø³Øª\n",
            "|Ù…ÛŒØ§Ù† Ø¨Ù†Ø¯Ú¯ÛŒ Ø±Ø§ Ø¨Ø¨Ø§ÛŒØ¯Øª Ø¨Ø³Øª\n",
            "|Ø®Ø±Ø¯ Ø±Ø§ Ùˆ Ø¬Ø§Ù† Ø±Ø§ Ù‡Ù…ÛŒ Ø³Ù†Ø¬Ø¯ Ø§ÙˆÛŒ\n",
            "|Ø¯Ø± Ø§Ù†Ø¯ÛŒØ´Ù‡Ù” Ø³Ø®ØªÙ‡ Ú©ÛŒ Ú¯Ù†Ø¬Ø¯ Ø§ÙˆÛŒ\n",
            "|Ø¨Ø¯ÛŒÙ† Ø¢Ù„Øª Ø±Ø§ÛŒ Ùˆ Ø¬Ø§Ù† Ùˆ Ø²Ø¨Ø§Ù†\n",
            "|Ø³ØªÙˆØ¯ Ø¢ÙØ±ÛŒÙ†Ù†Ø¯Ù‡ Ø±Ø§ Ú©ÛŒ ØªÙˆØ§Ù†\n",
            "|Ø¨Ù‡ Ù‡Ø³ØªÛŒØ´ Ø¨Ø§ÛŒØ¯ Ú©Ù‡ Ø®Ø³ØªÙˆ Ø´ÙˆÛŒ\n",
            "|Ø² Ú¯ÙØªØ§Ø± Ø¨ÛŒâ€ŒÚ©Ø§Ø± ÛŒÚ©Ø³Ùˆ Ø´ÙˆÛŒ\n",
            "|Ù¾Ø±Ø³ØªÙ†Ø¯Ù‡ Ø¨Ø§Ø´ÛŒ Ùˆ Ø¬ÙˆÛŒÙ†Ø¯Ù‡ Ø±Ø§Ù‡\n",
            "|Ø¨Ù‡ Ú˜Ø±ÙÛŒ Ø¨Ù‡ ÙØ±Ù…Ø§Ù†Ø´ Ú©Ø±Ø¯Ù† Ù†Ú¯Ø§Ù‡\n",
            "|ØªÙˆØ§Ù†Ø§ Ø¨ÙˆØ¯ Ù‡Ø± Ú©Ù‡ Ø¯Ø§Ù†Ø§ Ø¨ÙˆØ¯\n",
            "|Ø² Ø¯Ø§Ù†Ø´ Ø¯Ù„ Ù¾ÛŒØ± Ø¨Ø±Ù†Ø§ Ø¨ÙˆØ¯\n",
            "|Ø§Ø² Ø§ÛŒÙ† Ù¾Ø±Ø¯Ù‡ Ø¨Ø±ØªØ± Ø³Ø®Ù†â€ŒÚ¯Ø§Ù‡ Ù†ÛŒØ³Øª\n",
            "|Ø² Ù‡Ø³ØªÛŒ Ù…Ø± Ø§Ù†Ø¯ÛŒØ´Ù‡ Ø±Ø§ Ø±Ø§Ù‡ Ù†ÛŒØ³Øª\n",
            "|Ú©Ù†ÙˆÙ† Ø§ÛŒ Ø®Ø±Ø¯Ù…Ù†Ø¯ ÙˆØµÙ Ø®Ø±Ø¯\n",
            "|Ø¨Ø¯ÛŒÙ† Ø¬Ø§ÛŒÚ¯Ù‡ Ú¯ÙØªÙ† Ø§Ù†Ø¯Ø±Ø®ÙˆØ±Ø¯\n",
            "|Ú©Ù†ÙˆÙ† ØªØ§ Ú†Ù‡ Ø¯Ø§Ø±ÛŒ Ø¨ÛŒØ§Ø± Ø§Ø² Ø®Ø±Ø¯\n",
            "|Ú©Ù‡ Ú¯ÙˆØ´ Ù†ÛŒÙˆØ´Ù†Ø¯Ù‡ Ø²Ùˆ Ø¨Ø±Ø®ÙˆØ±Ø¯\n",
            "|Ø®Ø±Ø¯ Ø¨Ù‡ØªØ± Ø§Ø² Ù‡Ø± Ú†Ù‡ Ø§ÛŒØ²Ø¯ Ø¨Ø¯Ø§Ø¯\n",
            "|Ø³ØªØ§ÛŒØ´ Ø®Ø±Ø¯ Ø±Ø§ Ø¨Ù‡ Ø§Ø² Ø±Ø§Ù‡ Ø¯Ø§Ø¯\n",
            "|Ø®Ø±Ø¯ Ø±Ù‡Ù†Ù…Ø§ÛŒ Ùˆ Ø®Ø±Ø¯ Ø¯Ù„Ú¯Ø´Ø§ÛŒ\n",
            "|Ø®Ø±Ø¯ Ø¯Ø³Øª Ú¯ÛŒØ±Ø¯ Ø¨Ù‡ Ù‡Ø± Ø¯Ùˆ Ø³Ø±Ø§ÛŒ\n",
            "|Ø§Ø²Ùˆ Ø´Ø§Ø¯Ù…Ø§Ù†ÛŒ ÙˆØ²ÙˆÛŒØª ØºÙ…ÛŒØ³Øª\n",
            "|ÙˆØ²ÙˆÛŒØª ÙØ²ÙˆÙ†ÛŒ ÙˆØ²ÙˆÛŒØª Ú©Ù…ÛŒØ³Øª\n",
            "|Ø®Ø±Ø¯ ØªÛŒØ±Ù‡ Ùˆ Ù…Ø±Ø¯ Ø±ÙˆØ´Ù† Ø±ÙˆØ§Ù†\n",
            "|Ù†Ø¨Ø§Ø´Ø¯ Ù‡Ù…ÛŒ Ø´Ø§Ø¯Ù…Ø§Ù† ÛŒÚ© Ø²Ù…Ø§Ù†\n",
            "|Ú†Ù‡ Ú¯ÙØª Ø¢Ù† Ø®Ø±Ø¯Ù…Ù†Ø¯ Ù…Ø±Ø¯ Ø®Ø±Ø¯\n",
            "|Ú©Ù‡ Ø¯Ø§Ù†Ø§ Ø² Ú¯ÙØªØ§Ø± Ø§Ø² Ø¨Ø±Ø®ÙˆØ±Ø¯\n",
            "|Ú©Ø³ÛŒ Ú©Ùˆ Ø®Ø±Ø¯ Ø±Ø§ Ù†Ø¯Ø§Ø±Ø¯ Ø² Ù¾ÛŒØ´\n",
            "|Ø¯Ù„Ø´ Ú¯Ø±Ø¯Ø¯ Ø§Ø² Ú©Ø±Ø¯Ù‡Ù” Ø®ÙˆÛŒØ´ Ø±ÛŒØ´\n",
            "|Ù‡Ø´ÛŒÙˆØ§Ø± Ø¯ÛŒÙˆØ§Ù†Ù‡ Ø®ÙˆØ§Ù†Ø¯ ÙˆØ±Ø§\n",
            "|Ù‡Ù…Ø§Ù† Ø®ÙˆÛŒØ´ Ø¨ÛŒÚ¯Ø§Ù†Ù‡ Ø¯Ø§Ù†Ø¯ ÙˆØ±Ø§\n",
            "|Ø§Ø²ÙˆÛŒÛŒ Ø¨Ù‡ Ù‡Ø± Ø¯Ùˆ Ø³Ø±Ø§ÛŒ Ø§Ø±Ø¬Ù…Ù†Ø¯\n",
            "|Ú¯Ø³Ø³ØªÙ‡ Ø®Ø±Ø¯ Ù¾Ø§ÛŒ Ø¯Ø§Ø±Ø¯ Ø¨Ø¨Ù†Ø¯\n",
            "|Ø®Ø±Ø¯ Ú†Ø´Ù… Ø¬Ø§Ù†Ø³Øª Ú†ÙˆÙ† Ø¨Ù†Ú¯Ø±ÛŒ\n",
            "|ØªÙˆ Ø¨ÛŒâ€ŒÚ†Ø´Ù… Ø´Ø§Ø¯Ø§Ù† Ø¬Ù‡Ø§Ù† Ù†Ø³Ù¾Ø±ÛŒ\n",
            "|Ù†Ø®Ø³Øª Ø¢ÙØ±ÛŒÙ†Ø´ Ø®Ø±Ø¯ Ø±Ø§ Ø´Ù†Ø§Ø³\n",
            "|Ù†Ú¯Ù‡Ø¨Ø§Ù† Ø¬Ø§Ù†Ø³Øª Ùˆ Ø¢Ù† Ø³Ù‡ Ù¾Ø§Ø³\n",
            "|Ø³Ù‡ Ù¾Ø§Ø³ ØªÙˆ Ú†Ø´Ù… Ø§Ø³Øª ÙˆÚ¯ÙˆØ´ Ùˆ Ø²Ø¨Ø§Ù†\n",
            "|Ú©Ø²ÛŒÙ† Ø³Ù‡ Ø±Ø³Ø¯ Ù†ÛŒÚ© Ùˆ Ø¨Ø¯ Ø¨ÛŒâ€ŒÚ¯Ù…Ø§Ù†\n",
            "|\n"
          ]
        }
      ],
      "source": [
        "print(\"Preview of the text:\")\n",
        "print(dataset_info['preview_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def persian_normalizer(line: str) -> str:\n",
        "    space_pattern = re.compile(r\"[\\xad\\ufeff\\u200e\\u200d\\u200b\\x7f\\u202a\\u2003\\xa0\\u206e\\u200c\\x9d]\")\n",
        "    line = space_pattern.sub(\" \", line)\n",
        "    deleted_pattern = re.compile(r\"(\\d|[\\|\\[\\]]|\\\"|'Ù|[0-9]|Â¬|[a-zA-Z]|[Ø›â€œØŒ,â€â€˜Û”â€™â€™â€˜â€“]|[\\.Ã·+:\\-?Â»={}*Â«_â€¦\\ØŸ!/Ù€]|[Û²Û¹Û±Û·Û¸ÛµÛ¶Û´Û´Û³]|[\\\\u\\\\x]|[\\(\\)]|[Û°'Ù“Û«'Ù”]|[Ù“Ù”]|[Ù‹ÙŒÙÙ’ï¹¼ØŒÙŽÙÙÙ‘Â«Ù°Â»Ù–Ø¡]|\\[\\])\")\n",
        "    line = deleted_pattern.sub(\"\", line)\n",
        "    letter_dict = {\n",
        "        u\"Û€\": u\"Ù‡\", u\"Ø©\": u\"Øª\", u\"ÙŠ\": u\"ÛŒ\", u\"Ø¤\": u\"Ùˆ\", u\"Ø¥\": u\"Ø§\", u\"Ù¹\": u\"Øª\", \n",
        "        u\"Úˆ\": u\"Ø¯\", u\"Ø¦\": u\"ÛŒ\", u\"ï»¨\": u\"Ù†\", u\"ïº \": u\"Ø¬\", u\"ï»£\": u\"Ù…\", u\"ï·²\": u\"\", \n",
        "        u\"ï»³\": u\"ÛŒ\", u\"Ù»\": u\"Ø¨\", u\"Ù±\": u\"Ø§\", u\"Úµ\": u\"Ù„\", u\"ï­˜\": u\"Ù¾\", u\"ï»ª\": u\"Ù‡\", \n",
        "        u\"Úº\": u\"Ù†\", u\"Ù¶\": u\"Ùˆ\", u\"Ù²\": u\"Ø§\", u\"Û\": u\"Ù‡\", u\"ï»©\": u\"Ù‡\", u\"Ùƒ\": u\"Ú©\", \n",
        "        u\"ïº†\": u\"Ùˆ\", u\"Ø£\": u\"Ø§\", u\"ïºª\": u\"Ø¯\"}\n",
        "    letter_pattern = re.compile(r\"(\" + \"|\".join(letter_dict.keys()) + r\")\")\n",
        "    line = letter_pattern.sub(lambda x: letter_dict[x.group()], line)\n",
        "    return line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "normalizer = Normalizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_all_normalizations(line: str) -> str:\n",
        "    line = normalizer.correct_spacing(line)\n",
        "    line = normalizer.remove_diacritics(line)\n",
        "    line = normalizer.decrease_repeated_chars(line)\n",
        "    line = normalizer.persian_number(line)\n",
        "    line = persian_normalizer(line)\n",
        "    return line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data has been normalized and combined, saved to: D:\\\\UT\\\\Courses\\\\NLP\\\\2024-Fall\\\\NLP_Dr_Faili\\\\HWs\\\\HW1\\\\HDA\\\\Data\\\\Data_Out\\\\Normalized_ferdowsi.txt\n"
          ]
        }
      ],
      "source": [
        "def normalize_and_combine_lines(input_path: str, output_path: str):\n",
        "    with open(input_path, 'r', encoding='utf8') as f, open(output_path, 'w', encoding='utf8') as out_f:\n",
        "        lines = f.readlines()\n",
        "        cleaned_lines = [apply_all_normalizations(line.strip()) for line in lines if line.strip()]\n",
        "        combined_lines = [cleaned_lines[i] + \" | \" + cleaned_lines[i + 1] + \" |\" for i in range(0, len(cleaned_lines) - 1, 2)]\n",
        "        for line in combined_lines:\n",
        "            out_f.write(line + '\\n')\n",
        "normalize_and_combine_lines(Ferdowsi_Path, Normalized_ferdowsi_path)\n",
        "print(f\"Data has been normalized and combined, saved to: {Normalized_ferdowsi_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49609/49609 [00:00<00:00, 5441013.21it/s]\n"
          ]
        }
      ],
      "source": [
        "mesra_collection = [x.strip() for x in tqdm.tqdm(codecs.open(Normalized_ferdowsi_path, 'r', 'utf-8').readlines())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def HDA_Remove_Items(test_list, item):\n",
        "    return [i for i in test_list if i != item]\n",
        "mesra_collection = HDA_Remove_Items(mesra_collection, [])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = BertWordPieceTokenizer(clean_text=False, strip_accents=False, lowercase=False)\n",
        "tokenizer.train(files=[Normalized_ferdowsi_path], vocab_size=7500, min_frequency=2, show_progress=True)\n",
        "tokenizer.save(tokenizer_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(Normalized_ferdowsi_path, 'r', encoding='utf-8') as file:\n",
        "    normalized_text = file.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Examples:\n",
            "\n",
            "Original: Ø¨Ù‡ Ù†Ø§Ù… Ø®Ø¯Ø§ÙˆÙ†Ø¯ Ø¬Ø§Ù† Ùˆ Ø®Ø±Ø¯ | Ú©Ø²ÛŒÙ† Ø¨Ø±ØªØ± Ø§Ù†Ø¯ÛŒØ´Ù‡ Ø¨Ø±Ù†Ú¯Ø°Ø±Ø¯ |\n",
            "--------------------------------------------------\n",
            "Original: Ø®Ø¯Ø§ÙˆÙ†Ø¯ Ù†Ø§Ù… Ùˆ Ø®Ø¯Ø§ÙˆÙ†Ø¯ Ø¬Ø§ÛŒ | Ø®Ø¯Ø§ÙˆÙ†Ø¯ Ø±ÙˆØ²ÛŒ Ø¯Ù‡ Ø±Ù‡Ù†Ù…Ø§ÛŒ |\n",
            "--------------------------------------------------\n",
            "Original: Ø®Ø¯Ø§ÙˆÙ†Ø¯ Ú©ÛŒÙˆØ§Ù† Ùˆ Ú¯Ø±Ø¯Ø§Ù† Ø³Ù¾Ù‡Ø± | ÙØ±ÙˆØ²Ù†Ø¯Ù‡ Ù…Ø§Ù‡ Ùˆ Ù†Ø§Ù‡ÛŒØ¯ Ùˆ Ù…Ù‡Ø± |\n",
            "--------------------------------------------------\n",
            "Original: Ø² Ù†Ø§Ù… Ùˆ Ù†Ø´Ø§Ù† Ùˆ Ú¯Ù…Ø§Ù† Ø¨Ø±ØªØ±Ø³Øª | Ù†Ú¯Ø§Ø±Ù†Ø¯Ù‡ Ø¨Ø± Ø´Ø¯Ù‡ Ù¾ÛŒÚ©Ø±Ø³Øª |\n",
            "--------------------------------------------------\n",
            "Original: Ø¨Ù‡ Ø¨ÛŒÙ†Ù†Ø¯Ú¯Ø§Ù† Ø¢ÙØ±ÛŒÙ†Ù†Ø¯Ù‡ Ø±Ø§ | Ù†Ø¨ÛŒÙ†ÛŒ Ù…Ø±Ù†Ø¬Ø§Ù† Ø¯Ùˆ Ø¨ÛŒÙ†Ù†Ø¯Ù‡ Ø±Ø§ |\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "print(\"Original Examples:\\n\")\n",
        "for i in range(5):\n",
        "    print(f\"Original: {normalized_text[i].strip()}\\n{'-' * 50}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_poems = [\n",
        "    \"Ø¨Ù‡ Ù†Ø§Ù… Ø®Ø¯Ø§ÙˆÙ†Ø¯ Ø¬Ø§Ù† Ùˆ Ø®Ø±Ø¯\",\n",
        "    \"Ú©Ù‡ Ø§Ø² Ø§ÛŒÙ† Ø¨Ø±ØªØ± Ø§Ù†Ø¯ÛŒØ´Ù‡ Ø¨Ø±Ù†Ú¯Ø°Ø±Ø¯\",\n",
        "    \"Ø³Ø± Ù…Ø±Ø¯Ù…ÛŒ Ø¨Ø±Ø¯Ø¨Ø§Ø±ÛŒ Ø¨ÙˆØ¯\",\n",
        "    \"Ø³Ø¨Ú© Ø³Ø± Ù‡Ù…ÛŒØ´Ù‡ Ø¨Ù‡ Ø®ÙˆØ§Ø±ÛŒ Ø¨ÙˆØ¯\",\n",
        "    \"Ø¨Ù‡ Ù†Ø²Ø¯ Ú©Ù‡Ø§Ù† Ùˆ Ø¨Ù‡ Ù†Ø²Ø¯ Ù…Ù‡Ø§Ù†\",\n",
        "    \"Ø¨Ù‡ Ø§Ø°ÛŒØª Ù…ÙˆØ±ÛŒ Ù†ÛŒØ±Ø²Ø¯ Ø¬Ù‡Ø§Ù†\",\n",
        "    \"Ø¨Ù‡ Ø±Ù†Ú† Ø§Ø³Øª Ø§ÛŒ Ø®Ø±Ø¯Ù…Ù†Ø¯ Ú¯Ù†Ø¬\",\n",
        "    \"Ù†ÛŒØ§Ø¨Ø¯ Ú©Ø³ÛŒ Ú¯Ù†Ø­ Ù†Ø§Ø¨Ø±Ø¯Ù‡ Ø±Ù†Ø¬\",\n",
        "    \"Ø§ÛŒ Ø´Ø§Ù‡Ø¯ Ù‚Ø¯Ø³ÛŒØŒ Ú©Ù‡ Ú©Ø´Ø¯ Ø¨Ù†Ø¯ Ù†Ù‚Ø§Ø¨ØªØŸ\",\n",
        "    \"ÙˆÛŒ Ù…Ø±Øº Ø¨Ù‡Ø´ØªÛŒØŒ Ú©Ù‡ Ø¯Ù‡Ø¯ Ø¯Ø§Ù†Ù‡ Ùˆ Ø¢Ø¨ØªØŸ\",\n",
        "    \"Ø®ÙˆØ§Ø¨Ù… Ø¨Ø´Ø¯ Ø§Ø² Ø¯ÛŒØ¯Ù‡ Ø¯Ø± Ø§ÛŒÙ† ÙÚ©Ø± Ø¬Ú¯Ø±Ø³ÙˆØ²\",\n",
        "    \"Ú©Ø¢ØºÙˆØ´ Ú©Ù‡ Ø´Ø¯ Ù…Ù†Ø²Ù„ Ø¢Ø³Ø§ÛŒØ´ Ùˆ Ø®ÙˆØ§Ø¨ØªØŸ\",\n",
        "    \"Ø¯Ø±ÙˆÛŒØ´ Ù†Ù…ÛŒâ€ŒÙ¾Ø±Ø³ÛŒ Ùˆ ØªØ±Ø³Ù… Ú©Ù‡ Ù†Ø¨Ø§Ø´Ø¯\",\n",
        "    \"ØªØ±Ø§ Ø¯Ø§Ù†Ø´ Ùˆ Ø¯ÛŒÙ† Ø±Ù‡Ø§Ù†Ø¯ Ø¯Ø±Ø³Øª\",\n",
        "    \"Ø¯Ø± Ø±Ø³ØªÚ¯Ø§Ø±ÛŒ Ø¨Ø¨Ø§ÛŒØ¯Øª Ø¬Ø³Øª\",\n",
        "    \"ÙˆÚ¯Ø± Ø¯Ù„ Ù†Ø®ÙˆØ§Ù‡ÛŒ Ú©Ù‡ Ø¨Ø§Ø´Ø¯ Ù†Ú˜Ù†Ø¯\",\n",
        "    \"Ù†Ø®ÙˆØ§Ù‡ÛŒ Ú©Ù‡ Ø¯Ø§ÛŒÙ… Ø¨ÙˆÛŒ Ù…Ø³ØªÙ…Ù†Ø¯\",\n",
        "    \"Ø¨Ù‡ Ú¯ÙØªØ§Ø± Ù¾ÛŒØºÙ…Ø¨Ø±Øª Ø±Ø§Ù‡ Ø¬ÙˆÛŒ\",\n",
        "    \"Ø¯Ù„ Ø§Ø² ØªÛŒØ±Ú¯ÛŒÙ‡Ø§ Ø¨Ø¯ÛŒÙ† Ø¢Ø¨ Ø´ÙˆÛŒ\",\n",
        "    \"Ú†Ù‡ Ú¯ÙØª Ø¢Ù† Ø®Ø¯Ø§ÙˆÙ†Ø¯ ØªÙ†Ø²ÛŒÙ„ Ùˆ ÙˆØ­ÛŒ\",\n",
        "    \"Ø¨ÛŒØ§Ø±Ø§Ø³Øª Ú¯ÛŒØªÛŒ Ú†Ùˆ Ø¨Ø§Øº Ø¨Ù‡Ø§Ø±\",\n",
        "    \"Ø®Ø±Ø¯ Ø±Ù‡Ù†Ù…Ø§ÛŒ Ùˆ Ø®Ø±Ø¯ Ø¯Ù„Ú¯Ø´Ø§ÛŒ\",\n",
        "    \"Ø®Ø±Ø¯ Ø¯Ø³Øª Ú¯ÛŒØ±Ø¯ Ø¨Ù‡ Ù‡Ø± Ø¯Ùˆ Ø³Ø±Ø§ÛŒ\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original text: Ø¨Ù‡ Ù†Ø§Ù… Ø®Ø¯Ø§ÙˆÙ†Ø¯ Ø¬Ø§Ù† Ùˆ Ø®Ø±Ø¯\n",
            "Tokens: ['Ø¨Ù‡', 'Ù†Ø§Ù…', 'Ø®Ø¯Ø§ÙˆÙ†Ø¯', 'Ø¬Ø§Ù†', 'Ùˆ', 'Ø®Ø±Ø¯']\n",
            "--------------------------------------------------\n",
            "Original text: Ú©Ù‡ Ø§Ø² Ø§ÛŒÙ† Ø¨Ø±ØªØ± Ø§Ù†Ø¯ÛŒØ´Ù‡ Ø¨Ø±Ù†Ú¯Ø°Ø±Ø¯\n",
            "Tokens: ['Ú©Ù‡', 'Ø§Ø²', 'Ø§ÛŒÙ†', 'Ø¨Ø±ØªØ±', 'Ø§Ù†Ø¯ÛŒØ´Ù‡', 'Ø¨Ø±Ù†Ú¯Ø°Ø±Ø¯']\n",
            "--------------------------------------------------\n",
            "Original text: Ø³Ø± Ù…Ø±Ø¯Ù…ÛŒ Ø¨Ø±Ø¯Ø¨Ø§Ø±ÛŒ Ø¨ÙˆØ¯\n",
            "Tokens: ['Ø³Ø±', 'Ù…Ø±Ø¯Ù…ÛŒ', 'Ø¨Ø±Ø¯Ø¨Ø§Ø±ÛŒ', 'Ø¨ÙˆØ¯']\n",
            "--------------------------------------------------\n",
            "Original text: Ø³Ø¨Ú© Ø³Ø± Ù‡Ù…ÛŒØ´Ù‡ Ø¨Ù‡ Ø®ÙˆØ§Ø±ÛŒ Ø¨ÙˆØ¯\n",
            "Tokens: ['Ø³Ø¨Ú©', 'Ø³Ø±', 'Ù‡Ù…ÛŒØ´Ù‡', 'Ø¨Ù‡', 'Ø®ÙˆØ§Ø±ÛŒ', 'Ø¨ÙˆØ¯']\n",
            "--------------------------------------------------\n",
            "Original text: Ø¨Ù‡ Ù†Ø²Ø¯ Ú©Ù‡Ø§Ù† Ùˆ Ø¨Ù‡ Ù†Ø²Ø¯ Ù…Ù‡Ø§Ù†\n",
            "Tokens: ['Ø¨Ù‡', 'Ù†Ø²Ø¯', 'Ú©Ù‡Ø§Ù†', 'Ùˆ', 'Ø¨Ù‡', 'Ù†Ø²Ø¯', 'Ù…Ù‡Ø§Ù†']\n",
            "--------------------------------------------------\n",
            "Original text: Ø¨Ù‡ Ø§Ø°ÛŒØª Ù…ÙˆØ±ÛŒ Ù†ÛŒØ±Ø²Ø¯ Ø¬Ù‡Ø§Ù†\n",
            "Tokens: ['Ø¨Ù‡', 'Ø§', '##Ø°', '##ÛŒ', '##Øª', 'Ù…ÙˆØ±', '##ÛŒ', 'Ù†ÛŒØ±Ø²Ø¯', 'Ø¬Ù‡Ø§Ù†']\n",
            "--------------------------------------------------\n",
            "Original text: Ø¨Ù‡ Ø±Ù†Ú† Ø§Ø³Øª Ø§ÛŒ Ø®Ø±Ø¯Ù…Ù†Ø¯ Ú¯Ù†Ø¬\n",
            "Tokens: ['Ø¨Ù‡', 'Ø±', '##Ù†', '##Ú†', 'Ø§Ø³Øª', 'Ø§ÛŒ', 'Ø®Ø±Ø¯Ù…Ù†Ø¯', 'Ú¯Ù†Ø¬']\n",
            "--------------------------------------------------\n",
            "Original text: Ù†ÛŒØ§Ø¨Ø¯ Ú©Ø³ÛŒ Ú¯Ù†Ø­ Ù†Ø§Ø¨Ø±Ø¯Ù‡ Ø±Ù†Ø¬\n",
            "Tokens: ['Ù†ÛŒØ§Ø¨Ø¯', 'Ú©Ø³ÛŒ', 'Ú¯', '##Ù†', '##Ø­', 'Ù†Ø§Ø¨Ø±Ø¯Ù‡', 'Ø±Ù†Ø¬']\n",
            "--------------------------------------------------\n",
            "Original text: Ø§ÛŒ Ø´Ø§Ù‡Ø¯ Ù‚Ø¯Ø³ÛŒØŒ Ú©Ù‡ Ú©Ø´Ø¯ Ø¨Ù†Ø¯ Ù†Ù‚Ø§Ø¨ØªØŸ\n",
            "Tokens: ['Ø§ÛŒ', 'Ø´Ø§Ù‡', '##Ø¯', 'Ù‚Ø¯', '##Ø³ÛŒ', '[UNK]', 'Ú©Ù‡', 'Ú©Ø´Ø¯', 'Ø¨Ù†Ø¯', 'Ù†Ù‚', '##Ø§Ø¨', '##Øª', '[UNK]']\n",
            "--------------------------------------------------\n",
            "Original text: ÙˆÛŒ Ù…Ø±Øº Ø¨Ù‡Ø´ØªÛŒØŒ Ú©Ù‡ Ø¯Ù‡Ø¯ Ø¯Ø§Ù†Ù‡ Ùˆ Ø¢Ø¨ØªØŸ\n",
            "Tokens: ['ÙˆÛŒ', 'Ù…Ø±Øº', 'Ø¨Ù‡Ø´ØªÛŒ', '[UNK]', 'Ú©Ù‡', 'Ø¯Ù‡Ø¯', 'Ø¯Ø§Ù†Ù‡', 'Ùˆ', 'Ø¢Ø¨Øª', '[UNK]']\n",
            "--------------------------------------------------\n",
            "Original text: Ø®ÙˆØ§Ø¨Ù… Ø¨Ø´Ø¯ Ø§Ø² Ø¯ÛŒØ¯Ù‡ Ø¯Ø± Ø§ÛŒÙ† ÙÚ©Ø± Ø¬Ú¯Ø±Ø³ÙˆØ²\n",
            "Tokens: ['Ø®ÙˆØ§Ø¨', '##Ù…', 'Ø¨Ø´Ø¯', 'Ø§Ø²', 'Ø¯ÛŒØ¯Ù‡', 'Ø¯Ø±', 'Ø§ÛŒÙ†', 'Ù', '##Ú©Ø±', 'Ø¬Ú¯Ø±', '##Ø³ÙˆØ²']\n",
            "--------------------------------------------------\n",
            "Original text: Ú©Ø¢ØºÙˆØ´ Ú©Ù‡ Ø´Ø¯ Ù…Ù†Ø²Ù„ Ø¢Ø³Ø§ÛŒØ´ Ùˆ Ø®ÙˆØ§Ø¨ØªØŸ\n",
            "Tokens: ['Ú©Ø¢', '##Øº', '##ÙˆØ´', 'Ú©Ù‡', 'Ø´Ø¯', 'Ù…Ù†Ø²Ù„', 'Ø¢Ø³Ø§ÛŒØ´', 'Ùˆ', 'Ø®ÙˆØ§Ø¨', '##Øª', '[UNK]']\n",
            "--------------------------------------------------\n",
            "Original text: Ø¯Ø±ÙˆÛŒØ´ Ù†Ù…ÛŒâ€ŒÙ¾Ø±Ø³ÛŒ Ùˆ ØªØ±Ø³Ù… Ú©Ù‡ Ù†Ø¨Ø§Ø´Ø¯\n",
            "Tokens: ['Ø¯Ø±ÙˆÛŒØ´', '[UNK]', 'Ùˆ', 'ØªØ±Ø³Ù…', 'Ú©Ù‡', 'Ù†Ø¨Ø§Ø´Ø¯']\n",
            "--------------------------------------------------\n",
            "Original text: ØªØ±Ø§ Ø¯Ø§Ù†Ø´ Ùˆ Ø¯ÛŒÙ† Ø±Ù‡Ø§Ù†Ø¯ Ø¯Ø±Ø³Øª\n",
            "Tokens: ['ØªØ±Ø§', 'Ø¯Ø§Ù†Ø´', 'Ùˆ', 'Ø¯ÛŒÙ†', 'Ø±Ù‡Ø§Ù†Ø¯', 'Ø¯Ø±Ø³Øª']\n",
            "--------------------------------------------------\n",
            "Original text: Ø¯Ø± Ø±Ø³ØªÚ¯Ø§Ø±ÛŒ Ø¨Ø¨Ø§ÛŒØ¯Øª Ø¬Ø³Øª\n",
            "Tokens: ['Ø¯Ø±', 'Ø±Ø³Øª', '##Ú¯Ø§Ø±', '##ÛŒ', 'Ø¨Ø¨Ø§ÛŒØ¯Øª', 'Ø¬Ø³Øª']\n",
            "--------------------------------------------------\n",
            "Original text: ÙˆÚ¯Ø± Ø¯Ù„ Ù†Ø®ÙˆØ§Ù‡ÛŒ Ú©Ù‡ Ø¨Ø§Ø´Ø¯ Ù†Ú˜Ù†Ø¯\n",
            "Tokens: ['ÙˆÚ¯Ø±', 'Ø¯Ù„', 'Ù†Ø®ÙˆØ§Ù‡ÛŒ', 'Ú©Ù‡', 'Ø¨Ø§Ø´Ø¯', 'Ù†Ú˜Ù†Ø¯']\n",
            "--------------------------------------------------\n",
            "Original text: Ù†Ø®ÙˆØ§Ù‡ÛŒ Ú©Ù‡ Ø¯Ø§ÛŒÙ… Ø¨ÙˆÛŒ Ù…Ø³ØªÙ…Ù†Ø¯\n",
            "Tokens: ['Ù†Ø®ÙˆØ§Ù‡ÛŒ', 'Ú©Ù‡', 'Ø¯', '##Ø§ÛŒÙ…', 'Ø¨ÙˆÛŒ', 'Ù…Ø³ØªÙ…Ù†Ø¯']\n",
            "--------------------------------------------------\n",
            "Original text: Ø¨Ù‡ Ú¯ÙØªØ§Ø± Ù¾ÛŒØºÙ…Ø¨Ø±Øª Ø±Ø§Ù‡ Ø¬ÙˆÛŒ\n",
            "Tokens: ['Ø¨Ù‡', 'Ú¯ÙØªØ§Ø±', 'Ù¾ÛŒØºÙ…Ø¨Ø±', '##Øª', 'Ø±Ø§Ù‡', 'Ø¬ÙˆÛŒ']\n",
            "--------------------------------------------------\n",
            "Original text: Ø¯Ù„ Ø§Ø² ØªÛŒØ±Ú¯ÛŒÙ‡Ø§ Ø¨Ø¯ÛŒÙ† Ø¢Ø¨ Ø´ÙˆÛŒ\n",
            "Tokens: ['Ø¯Ù„', 'Ø§Ø²', 'ØªÛŒØ±Ú¯ÛŒÙ‡Ø§', 'Ø¨Ø¯ÛŒÙ†', 'Ø¢Ø¨', 'Ø´ÙˆÛŒ']\n",
            "--------------------------------------------------\n",
            "Original text: Ú†Ù‡ Ú¯ÙØª Ø¢Ù† Ø®Ø¯Ø§ÙˆÙ†Ø¯ ØªÙ†Ø²ÛŒÙ„ Ùˆ ÙˆØ­ÛŒ\n",
            "Tokens: ['Ú†Ù‡', 'Ú¯ÙØª', 'Ø¢Ù†', 'Ø®Ø¯Ø§ÙˆÙ†Ø¯', 'ØªÙ†', '##Ø²ÛŒ', '##Ù„', 'Ùˆ', 'Ùˆ', '##Ø­', '##ÛŒ']\n",
            "--------------------------------------------------\n",
            "Original text: Ø¨ÛŒØ§Ø±Ø§Ø³Øª Ú¯ÛŒØªÛŒ Ú†Ùˆ Ø¨Ø§Øº Ø¨Ù‡Ø§Ø±\n",
            "Tokens: ['Ø¨ÛŒØ§Ø±Ø§Ø³Øª', 'Ú¯ÛŒØªÛŒ', 'Ú†Ùˆ', 'Ø¨Ø§Øº', 'Ø¨Ù‡Ø§Ø±']\n",
            "--------------------------------------------------\n",
            "Original text: Ø®Ø±Ø¯ Ø±Ù‡Ù†Ù…Ø§ÛŒ Ùˆ Ø®Ø±Ø¯ Ø¯Ù„Ú¯Ø´Ø§ÛŒ\n",
            "Tokens: ['Ø®Ø±Ø¯', 'Ø±Ù‡Ù†Ù…Ø§ÛŒ', 'Ùˆ', 'Ø®Ø±Ø¯', 'Ø¯Ù„Ú¯Ø´Ø§ÛŒ']\n",
            "--------------------------------------------------\n",
            "Original text: Ø®Ø±Ø¯ Ø¯Ø³Øª Ú¯ÛŒØ±Ø¯ Ø¨Ù‡ Ù‡Ø± Ø¯Ùˆ Ø³Ø±Ø§ÛŒ\n",
            "Tokens: ['Ø®Ø±Ø¯', 'Ø¯Ø³Øª', 'Ú¯ÛŒØ±Ø¯', 'Ø¨Ù‡', 'Ù‡Ø±', 'Ø¯Ùˆ', 'Ø³Ø±Ø§ÛŒ']\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for poem in sample_poems:\n",
        "    encoded = tokenizer.encode(poem)\n",
        "    tokens = encoded.tokens\n",
        "    print(f\"Original text: {poem}\")\n",
        "    print(f\"Tokens: {tokens}\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 3.1: **N-Gram & Previous Tokenizer**<a name=\"NGRAM_Pre_Tok\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import collections\n",
        "import random\n",
        "import itertools\n",
        "import math\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "import collections\n",
        "import random\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Hosein_GRAM:\n",
        "    def __init__(self, tokens, order, enable_preprocessing=True, is_primary=True):\n",
        "        self.order = order\n",
        "        self.enable_preprocessing = enable_preprocessing\n",
        "        self.is_primary = is_primary\n",
        "        self.ngrams = collections.defaultdict(collections.Counter)\n",
        "        self.tokens = tokens\n",
        "        self.backoff_models = []\n",
        "\n",
        "        processed_tokens = self._preprocess_tokens(tokens) if enable_preprocessing else tokens\n",
        "\n",
        "        self._build_ngrams(processed_tokens)\n",
        "\n",
        "        if is_primary:\n",
        "            self._initialize_backoff(processed_tokens)\n",
        "\n",
        "    def _preprocess_tokens(self, tokens):\n",
        "        return ['<SOS>'] * self.order + tokens + ['<EOS>'] * self.order\n",
        "\n",
        "    def _build_ngrams(self, tokens):\n",
        "        if self.order == 1:\n",
        "            for token in tokens:\n",
        "                self.ngrams[()][token] += 1\n",
        "        else:\n",
        "            for i in range(len(tokens) - self.order):\n",
        "                window = tokens[i:i + self.order]\n",
        "                prefix = tuple(window[:-1])\n",
        "                suffix = window[-1]\n",
        "                self.ngrams[prefix][suffix] += 1\n",
        "\n",
        "    def _initialize_backoff(self, tokens):\n",
        "        for reduced_order in range(1, self.order):\n",
        "            model = Hosein_GRAM(tokens, self.order - reduced_order, self.enable_preprocessing, False)\n",
        "            self.backoff_models.append(model)\n",
        "\n",
        "    def predict_next_token(self, context):\n",
        "        context_extended = ['<SOS>'] * (self.order - 1) + context\n",
        "        context_key = tuple(context_extended[-(self.order - 1):])\n",
        "        suffixes = self.ngrams[context_key]\n",
        "        if suffixes:\n",
        "            return random.choices(list(suffixes.keys()), weights=suffixes.values())[0]\n",
        "        elif self.is_primary and self.backoff_models:\n",
        "            return self._backoff(context)\n",
        "        return \"<EOS>\"\n",
        "\n",
        "    def _backoff(self, context):\n",
        "        for model in self.backoff_models:\n",
        "            next_token = model.predict_next_token(context)\n",
        "            if next_token != \"<EOS>\":\n",
        "                return next_token\n",
        "        return \"<EOS>\"\n",
        "\n",
        "    def probability_of(self, sequence):\n",
        "        if len(sequence) < self.order:\n",
        "            return 0.000001\n",
        "\n",
        "        context = tuple(sequence[-self.order:-1])\n",
        "        token = sequence[-1]\n",
        "        if token in self.ngrams[context]:\n",
        "            return self.ngrams[context][token] / sum(self.ngrams[context].values())\n",
        "        elif self.is_primary and self.backoff_models:\n",
        "            return self._backoff_probability(sequence)\n",
        "        return 0.000001\n",
        "\n",
        "    def _backoff_probability(self, sequence):\n",
        "        for model in self.backoff_models:\n",
        "            probability = model.probability_of(sequence)\n",
        "            if probability > 0.000001:\n",
        "                return probability\n",
        "        return 0.000001\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 3.1: **Train Model & Text Generation**<a name=\"Train_Gernerate\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "N-Gram models are a popular approach to language modeling, particularly for their simplicity and interpretability. However, as the value of N increases, several challenges arise that significantly affect the performance, efficiency, and accuracy of these models. Below is a detailed exploration of these challenges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training 2-gram model...\n",
            "Training 4-gram model...\n",
            "Training 8-gram model...\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "2-gram generated text:\n",
            "Ø³Ø¨Ú© Ø³Ø± Ù‡Ù…ÛŒØ´Ù‡ Ø¨Ù‡ Ø®ÙˆØ§Ø±ÛŒ Ø¨ÙˆØ¯ Ù‡Ø§Ù…ÙˆÙ† Ø³ÙˆÛŒ Ú†Ø´Ù…Ù‡ Ø¹Ù†Ø¨Ø± Ù‡Ù…ÛŒ Ú¯ÙØª Ú©Ø§ÛŒ Ú©Ø±Ø¯Ú¯Ø§Ø± | Ú©Ø³ÛŒ Ú©Ø´ | Ù‡Ù…Ù‡ Ù¾Ø§Ø±Ø³ Ú¯Ø±Ø¯ Ø±Ø²Ù… Ùˆ Ú¯Ø´ØªÙ†Ø¯ ÙˆÙ…Ù‡ Ø³Ø§Ù„ Ø¨ÛŒØ´ Ø§Ùˆ Ú©Ø±Ø¯ | Ø¨Ø±Ø§ÙˆÛŒ | Ú†Ùˆ Ø¨Ù‡Ø±Ø§Ù… Ø¨Ø®Ø´ÛŒØ¯ Ø¨Ø³ÛŒØ§Ø± Ù…Ø± Ø§ÙˆØ±Ø§Ø³Øª | Ú©Ù‡ Ø¨Ø§Ú¯ÙØª | Ø² Ø±ÙˆÙ… Ø§ÛŒØ±Ø§ | ØªØ±Ø§ | Ø¨Ù…Ø±Ø¯ | Ù†ÛŒØ§Ù…Ø¯ Ú†Ù†ÙˆÛŒ Ø§Ø² Ø¬Ù†Ú¯ Ø§ÛŒÙ† Ú©Ø³ Ú©Ù‡ Ù…Ø§ Ø¯Ø± Ø²Ø§ÙˆÙ„Ø³ØªØ§Ù† Ø³ÙˆÛŒ Ø§Ùˆ Ø¨Ù‡ Ø¢Ø¨ Ø²Ø±Ø¯ | Ú©Ø±Ø§ Ø®Ø³ØªÙ‡ Ø±ÙˆØ²Ú¯Ø§Ø± Ú©Ù‡Ù† | Ù…ÛŒØ§Ù†Ø´ ÛŒÚ©ÛŒ Ù¾ÛŒØ´ Ø±Ùˆ Ù¾ÛŒØ´ Ø§ÛŒØ´Ø§Ù† Ø¬Ø¯Ø§ Ú©Ø±Ø¯ | Ù¾Ø´ÛŒÙ…Ø§Ù† Ù…Ø¨Ø§Ø¯ÛŒ Ù‡Ù…ÛŒØ´Ù‡ Ø®Ø±Ø¯ Ø¨Ø± Ø¬Ø§ÛŒ Ú©Ø±Ø¯ ØºØ§Ø±Øª Ùˆ Ú¯Ø± Ø¨ÛŒÙ†Ø¯ Ø¨Ù…Ù† | Ú†ØºØ§Ù†ÛŒ Ú©Ù‡ Ø¢Ù…Ø¯ Ø¨Ù‡ Ú¯ÙØªØ§Ø± Ø±Ø§Ø³Øª | Ú†Ù‡Ø§Ø±Ù… Ú†Ù†ÛŒÙ† Ø§Ø² Ø¨Ø±Ú¯ | Ú†Ùˆ Ø¢ØªØ´ Ù†Ù‡Ø§Ø¯Ù‡ Ø¨Ø¯ÙˆØ´ | Ú†Ù†ÛŒÙ† Ø¯Ø§Ø¯ Ùˆ Ù¾Ø±Ù…Ø§ÛŒÙ‡ Ø¬ÙˆÛŒ Ø±Ø§ Ù†ÛŒØ³Øª Ø±Ø§ÛŒ | Ú©Ù‡ Ø¯ÛŒØ¯ÛŒ ØªÙˆ Ø³ÙˆÚ©ÙˆØ§Ø± | Ø³Ø±Ø§Ù†Ø¬Ø§Ù… Ø¨Ø³ØªØ± Ø¨ÙˆØ¯ Ø§Ø² Ø§ÛŒØ±Ø§Ù† Ú¯Ø°Ø´ØªÛŒ Ú†Ù‡ Ø¯ÛŒÙ†Ø§Ø± Ø¨Ø± Ú©Ù…Ù†Ø¯ Ø¯Ø±Ø§Ø² | Ø¨Ù†Ø§Ú©Ø§Ù… Ù„Ø´Ú©Ø± Ø¨Ø±Ø§Ù†Ø¯ | Ø¨ÙØ±Ù…ÙˆØ¯ ØªØ§ Ø´Ø¨ ØªÛŒØ±Ù‡ Ú©ÙˆÙ‡ ØªØ§ Ø¨Ø¯Ø§Ù†Ø³Øª Ù„Ù‡Ø§Ú© Ùˆ Ù¾Ø§Ø±Ø³Ø§ | Ø®Ø¬Ø³ØªÙ‡ Ø¨Ø¯Ø³Øª Ú†Ù¾Ø´ Ù…ØµØ± Ø§Ù†Ø¯Ø±ÙˆÙ† Ø³Ø± Ø¨Ù‡ Ø³Ø± ÙØ±Ø§Ø²Ø¯ Ø¨Ù‡Ø± ØªÙˆ Ø¨Ø³ØªÙ† Ù¾Ù‡Ù„ÙˆÛŒ | Ú©Ø³ÛŒ Ú©Ø´ Ùˆ Ø¨Ø³ | Ù‡Ù…Ù‡ Ø§Ù†Ø¬Ù…Ù† | Ú†Ùˆ Ø³Ù†Ú¯ | Ú©Ù‡ Ù…Ø§ Ø² Ø¯Ø±Ø¯ Ø¨Ø§Ø¨ | Ù¾Ø´ÛŒÙ…Ø§Ù†ÛŒ Ùˆ Ø¢Ù† Ù†Ø§Ù…Ù‡ ÛŒÙ„ Ø²Ø§Ø¨Ù„ÛŒØ³Øª | Ø³ØªÙˆØ± | ÛŒÚ©ÛŒ Ù…Ù†\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "4-gram generated text:\n",
            "Ø³Ø¨Ú© Ø³Ø± Ù‡Ù…ÛŒØ´Ù‡ Ø¨Ù‡ Ø®ÙˆØ§Ø±ÛŒ Ø¨ÙˆØ¯ | Ú¯Ù‡ Ø¢Ø´ØªÛŒ Ø¨Ø±Ø¯Ø¨Ø§Ø±ÛŒ Ø¨ÙˆØ¯ | Ø³Ø¨Ú© Ø³Ø± Ø³ÙˆÛŒ Ú¯Ù†Ø¬ Ø¢Ú¯Ù†Ø¯Ù‡ Ú©Ø±Ø¯ | Ø§Ø²Ø§Ù† Ù¾Ø³ Ø¬Ù‡Ø§Ù†Ø¬ÙˆÛŒ Ø®Ø³ØªÙ‡ Ø¬Ú¯Ø± | Ø§Ú¯Ø± Ø¬Ù†Ú¯ Ø¬ÙˆÛŒÙ… Ú†Ù‡ Ø¯Ø±ÛŒØ§ Ú†Ù‡ Ú©ÙˆÙ‡ | Ú†Ùˆ Ú¯Ø±Ø¯ÙˆÙ† Ø¨Ù¾ÙˆØ´ÛŒØ¯ Ú†ÛŒÙ†ÛŒ Ø­Ø±ÛŒØ± | Ø² Ù…ØµØ±ÛŒ Ùˆ Ù¾Ø§Ø±Ø³ÛŒ | Ø² Ø³ÛŒ Ú©Ø±Ø¯ Ø¯Ø§Ù†Ù†Ø¯Ù‡ Ù…ÙˆØ¨Ø¯ Ú†Ù‡Ø§Ø± | ÙˆØ²ÛŒÙ† Ú†Ø§Ø± Ø¨Ù‡Ø±Ø§Ù… Ø¨Ø¯ Ø´Ù‡Ø±ÛŒØ§Ø± | Ø¯Ø±Ø®ØªÛŒØ³Øª Ø®Ù†Ú¯ÛŒ Ù‡Ù…ÛŒØ´Ù‡ Ø¨Ù‡ Ø¨Ø§Ø± | Ø² Ø¨Ø§Øº Ù…Ù† Ø¢ÙˆØ§Ø±Ù‡ Ø´Ø¯ Ù†Ø§Ù…Ø¯Ø§Ø± | Ø¨Ø±ÙØª Ùˆ Ø¨Ù¾ÛŒÙ…ÙˆØ¯ Ø¨Ø§Ù„Ø§ÛŒ Ø´Ø¨ | Ù¾Ø± Ø§Ù†Ø¯ÛŒØ´Ù‡ Ø´Ø¯ Ø²Ø§Ù„ Ø²Ø± | Ù¾Ø±Ø³ØªÙ†Ø¯Ù‡ Ø¨Ø§ Ø§Ùˆ ÛŒÚ©ÛŒ Ø®ÙˆØ¨ Ø±Ø§ÛŒ | Ø¨Ø±Ø§Ù† Ø±Ùˆ Ú©Ù‡ ÙØ±Ù…Ø§Ù† Ø¯Ù‡Ø¯ Ø´Ù‡Ø±ÛŒØ§Ø± | Ø¨Ø³Ø§Ø²Ø¯ ÛŒÚ©ÛŒ Ù„Ø´Ú©Ø± Ù†Ø§Ù…Ø¯Ø§Ø± | Ù‡Ù…ÛŒ Ú¯Ø±Ø² Ø¨Ø§Ø±ÛŒØ¯ Ùˆ Ù¾ÙˆÙ„Ø§Ø¯ ØªÛŒØº | Ú†Ùˆ Ø¯Ø±ÛŒØ§ Ø¨Ø±Ø¢Ø´ÙØª Ù…Ø±Ø¯ Ø¬ÙˆØ§Ù† | Ú©Ù‡ Ù…Ù† Ù¾ÙˆØ± Ø³Ø§Ø³Ø§Ù†Ù… Ø§ÛŒ Ù¾Ù‡Ù„ÙˆØ§Ù† | Ù¾ÛŒØ§Ù… Ø¢ÙˆØ±ÛŒØ¯Ù… Ø¨Ù‡ Ø±ÙˆØ´Ù† Ø±ÙˆØ§Ù† | Ø¨Ù‡ Ù‡Ø±Ù…Ø²Ø¯ Ù†Ø§Ø³Ø§Ù„Ø®ÙˆØ±Ø¯Ù‡ Ø¬ÙˆØ§Ù† | ÛŒÚ©ÛŒ Ù¾Ø±Ù‡Ù†Ø± Ø¨ÙˆØ¯ Ùˆ Ø±ÙˆØ´Ù† Ø±ÙˆØ§Ù† | Ø¨Ø±Ø¢Ù…Ø¯ ØªØ±Ø§ Ø§ÛŒÙ† Ú†Ù†ÛŒÙ† Ú©Ø§Ø± Ú†Ù†Ø¯ | Ø¨Ù†ÛŒØ±ÙˆÛŒ ÛŒØ²Ø¯Ø§Ù† Ùˆ Ø¨Ø®Øª Ø¨Ù„Ù†Ø¯ | Ø² Ø³Ø§Ù†Ø¯ Ø¨Ø±ÙˆÙ… Ùˆ Ø¨Ù‡ Ø§ÛŒØ±Ø§Ù† Ú¯Ø²Ù†Ø¯ | Ù†Ø®Ø³Øª Ø§Ù†Ø¯Ø± Ø¢ÛŒÙ… Ø² Ø®Ø§Ù‚Ø§Ù† Ú†ÛŒÙ† Ú†Ù†Ø¯ Ø¨Ø§ Ø§Ùˆ Ø¨Ø±Ø§Ù†Ø¯ | Ø¨Ø¯Ùˆ Ú¯ÙØª Ø´Ø§Ù‡ Ø§ÛŒ Ø®Ø±Ø¯Ù…Ù†Ø¯ Ù¾ÛŒØ± | Ù…Ù†Ù‡ Ø²Ù‡Ø± Ø¨Ø±Ù†Ø¯Ù‡ Ø¨Ø± Ø¬Ø§Ù… Ø´ÛŒØ± | Ø¨Ù†Ù‡ ØªÛŒØº Ùˆ Ø¨Ú¯Ø´Ø§ÛŒ Ø² Ø¢Ù‡Ù† Ù…ÛŒØ§Ù†\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "8-gram generated text:\n",
            "Ø³Ø¨Ú© Ø³Ø± Ù‡Ù…ÛŒØ´Ù‡ Ø¨Ù‡ Ø®ÙˆØ§Ø±ÛŒ Ø¨ÙˆØ¯ | Ù‡Ø±Ø§Ù†Ú©Ø³ Ú©Ù‡ Ú¯Ø´Øª Ø§ÛŒÙ…Ù† Ø§Ùˆ Ø´Ø§Ø¯ Ø´Ø¯ | ØºÙ… Ùˆ Ø±Ù†Ø¬ Ø¨Ø§ Ø§ÛŒÙ…Ù†ÛŒ Ø¨Ø§Ø¯ Ø´Ø¯ | ØªÙˆØ§Ù†Ú¯Ø± ØªØ± Ø¢Ù† Ú©Ùˆ Ø¯Ù„ÛŒ Ø±Ø§Ø¯ Ø¯Ø§Ø´Øª | Ø¯Ø±Ù… Ú¯Ø±Ø¯ Ú©Ø±Ø¯Ù† Ø¨Ù‡ Ø¯Ù„ Ø¨Ø§Ø¯ Ø¯Ø§Ø´Øª | Ø§Ú¯Ø± Ù†ÛŒØ³ØªØª Ú†ÛŒØ² Ù„Ø®ØªÛŒ Ø¨ÙˆØ±Ø² | Ú©Ù‡ Ø¨ÛŒ Ú†ÛŒØ² Ú©Ø³ Ø±Ø§ Ù†Ø¯Ø§Ø±Ù†Ø¯ Ø§Ø±Ø² | Ù…Ø±ÙˆØª Ù†ÛŒØ§Ø¨Ø¯ Ú©Ø±Ø§ Ú†ÛŒØ² Ù†ÛŒØ³Øª | Ù‡Ù…Ø§Ù† Ø¬Ø§Ù‡ Ù†Ø²Ø¯ Ú©Ø³Ø´ Ù†ÛŒØ² Ù†ÛŒØ³Øª | Ú†Ùˆ Ø®Ø´Ù†ÙˆØ¯ Ø¨Ø§Ø´ÛŒ ØªÙ† Ø¢Ø³Ø§Ù† Ø´ÙˆÛŒ | ÙˆÚ¯Ø± Ø¢Ø² ÙˆØ±Ø²ÛŒ Ù‡Ø±Ø§Ø³Ø§Ù† Ø´ÙˆÛŒ | Ù†Ù‡ Ú©ÙˆØ´ÛŒØ¯Ù†ÛŒ Ú©Ø§Ù† Ø¨Ø±Ø¢Ø±Ø¯ Ø¨Ù‡ Ø±Ù†Ø¬ | Ø±ÙˆØ§Ù† Ø±Ø§ Ø¨Ù‡ Ù¾ÛŒÚ†Ø§Ù†Ø¯ Ø§Ø² Ø¢Ø² Ú¯Ù†Ø¬ | Ø² Ú©Ø§Ø± Ø²Ù…Ø§Ù†Ù‡ Ù…ÛŒØ§Ù†Ù‡ Ú¯Ø²ÛŒÙ† | Ú†Ùˆ Ø®ÙˆØ§Ù‡ÛŒ Ú©Ù‡ ÛŒØ§Ø¨ÛŒ Ø¨Ø¯Ø§Ø¯ Ø¢ÙØ±ÛŒÙ† | Ú©Ù‡ Ù†ÛŒÚ© Ùˆ Ø¨Ø¯ Ø§Ù†Ø¯Ø± Ø¬Ù‡Ø§Ù† Ø¨Ú¯Ø°Ø±Ø¯ | Ø²Ù…Ø§Ù†Ù‡ Ø¯Ù… Ù…Ø§ Ù‡Ù…ÛŒ Ø¨Ø´Ù…Ø±Ø¯ | Ú©Ù‡ Ú¯ÙˆÛŒØ¯ Ú©Ú˜ÛŒ Ø¨Ù‡ Ø§Ø² Ø±Ø§Ø³ØªÛŒ | Ø¨Ú©Ú˜ÛŒ Ú†Ø±Ø§ Ø¯Ù„ Ø¨ÛŒØ§Ø±Ø§Ø³ØªÛŒ | Ú†Ùˆ ÙØ±Ù…Ø§Ù† Ú©Ù†ÛŒ Ù‡Ø±Ú† Ø®ÙˆØ§Ù‡ÛŒ ØªÙˆ Ø±Ø§Ø³Øª | ÛŒÚ©ÛŒ Ø¨Ù‡Ø± Ø§Ø²ÛŒÙ† Ù¾Ø§Ø¯Ø´Ø§Ù‡ÛŒ ØªÙˆ Ø±Ø§Ø³Øª | Ø¨Ø¯ÛŒÙ† Ú¯ÛŒØªÛŒ Ø§Ù†Ø¯Ø± Ø¨Ø²ÛŒ Ø´Ø§Ø¯Ù…Ø§Ù† | ØªÙ† Ø¢Ø³Ø§Ù† Ùˆ Ø¯ÙˆØ± Ø§Ø² Ø¨Ø¯ Ø¨Ø¯Ú¯Ù…Ø§Ù† | ÙˆÚ¯Ø± Ø¨Ú¯Ø°Ø±ÛŒ Ø²ÛŒÙ† Ø³Ø±Ø§ÛŒ Ø³Ù¾Ù†Ø¬ | Ú¯Ù‡ Ø¨Ø§Ø²Ú¯Ø´ØªÙ† Ù†Ø¨Ø§Ø´ÛŒ Ø¨Ù‡ Ø±Ù†Ø¬ | Ù†Ø´Ø§ÛŒØ¯ Ú©Ø²ÛŒÙ† Ú©Ù… Ú©Ù†ÛŒÙ… Ø§Ø±ÙØ²ÙˆÙ† | Ú©Ù‡ Ø²Ø±Ø¯Ø´Øª Ú¯ÙˆÛŒØ¯ Ø¨Ø²Ù†Ø¯ Ø§Ù†Ø¯Ø±ÙˆÙ† | Ú©Ù‡ Ù‡Ø±Ú©Ø³ Ú©Ù‡ Ø¨Ø±Ú¯Ø±Ø¯Ø¯ Ø§Ø²\n",
            "----------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with open(Normalized_ferdowsi_path, 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "tokens = tokenizer.encode(text).tokens\n",
        "ns = [2, 4, 8]\n",
        "models = []\n",
        "for n in ns:\n",
        "    print(f\"Training {n}-gram model...\")\n",
        "    model = Hosein_GRAM(tokens, n)\n",
        "    models.append(model)\n",
        "seed_text = \"Ø³Ø¨Ú© Ø³Ø± Ù‡Ù…ÛŒØ´Ù‡ Ø¨Ù‡ Ø®ÙˆØ§Ø±ÛŒ Ø¨ÙˆØ¯\".split()\n",
        "num_tokens = 200\n",
        "for model, n in zip(models, ns):\n",
        "    generated_text = seed_text[:]\n",
        "    while len(generated_text) < num_tokens:\n",
        "        next_token = model.predict_next_token(generated_text[-(n - 1):])\n",
        "        if next_token != \"[UNK]\" and next_token != \"<EOS>\":\n",
        "            generated_text.append(next_token)\n",
        "        if next_token == \"<EOS>\":\n",
        "            break\n",
        "    print(\"\\n\" + \"-\" * 40) \n",
        "    print(f\"\\n{n}-gram generated text:\")\n",
        "    print(\" \".join(generated_text).replace(\"[UNK]\", \"\").replace(\" ##\", \"\"))\n",
        "    print(\"-\" * 40 + \"\\n\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 3.Analysis: **Analysis of Generated Text**<a name=\"Analysis_Gernerate\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **2-gram Model(BiGRAM)**\n",
        "\n",
        "    - The text produced by the 2-gram model appears relatively coherent but lacks logical continuity between sentences. This model, with its short-term view (considering only the previous word), struggles to produce complex and meaningful longer structures.\n",
        "\n",
        "- **4-gram Model**\n",
        "\n",
        "    - This model shows a better ability to generate text with more logical and continuous structures. Its capability to follow syntactic and grammatical rules of Persian is improved over the 2-gram model, thanks to its broader context understanding, encompassing four words.\n",
        "\n",
        "- **8-gram Model**\n",
        "\n",
        "    - The 8-gram model excels in producing fully coherent texts with deeper logical connections between sentences. It manages to generate complex structures that utilize the Persian language more effectively, indicative of its capacity to incorporate extended contextual information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 3.3: **Big N in N-GRAM & Challenges** <a name=\"Big_N_in_NGRAM\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 1. **Exponential Growth of N-Grams**\n",
        "    \n",
        "    - As we increase the value of N, the number of possible combinations of words (N-Grams) grows extremely fast. For example, if we have a vocabulary of 10,000 unique words, the number of possible N-Grams becomes huge as we look at longer sequences like 5-grams or 8-grams.\n",
        "    \n",
        "    - This causes two major problems:\n",
        "        - **Storage issues:** The model needs to keep track of all these N-Grams, which requires a lot of memory.\n",
        "        - **Data sparsity:** Many of these N-Grams may never appear in the dataset, or they appear only once or twice. This means we donâ€™t have enough data to reliably estimate their probabilities.\n",
        "\n",
        "- 2. **Smoothing Difficulties**\n",
        "    \n",
        "    - Smoothing is a technique used to handle cases where some N-Grams don't appear in the training data. It helps prevent the model from assigning a zero probability to sequences it has never seen. However, as N gets larger, smoothing becomes harder to apply effectively.\n",
        "    \n",
        "    - Hereâ€™s why:\n",
        "    \n",
        "        - **More combinations:** As N increases, there are more N-Grams that need smoothing. This increases the computational cost.\n",
        "        \n",
        "        - **Less reliable adjustments:** For large N, smoothing may not make much of a difference because so many N-Grams are missing from the training data. This can lead to the model assigning probabilities that donâ€™t reflect the true language patterns.\n",
        "\n",
        "- 3. **Increased Computational Requirements**\n",
        "    \n",
        "    - The bigger the value of N, the more resources we need to build and run the model. This affects:\n",
        "       \n",
        "        - **Time to train:** It takes much longer to process larger N-Grams because there are more sequences to count and analyze.\n",
        "\n",
        "        - **Memory usage:** Storing all these N-Grams and their probabilities in memory can quickly become impractical, especially with larger datasets.\n",
        "        \n",
        "        - **Querying speed:** When we ask the model to predict the next word, it takes longer to search through all the possible N-Grams for larger N, which slows down the process.\n",
        "\n",
        "- 4. **Data Sparsity and Overfitting**\n",
        "    - For large values of N, we run into the problem of data sparsity. This means that most of the possible N-Grams are never seen in the training data. When this happens, the model becomes too focused on memorizing the specific sequences it has seen, rather than learning the general patterns of the language. This leads to:\n",
        "        \n",
        "        - **Overfitting:** The model performs well on the training data but poorly on new, unseen text.\n",
        "        \n",
        "        - **Unreliable predictions:** Since many N-Grams donâ€™t have enough examples in the data, the modelâ€™s predictions become less accurate.\n",
        "\n",
        "- 5. **Limited Understanding of Long-Term Dependencies**\n",
        "    \n",
        "    - While increasing N helps the model consider longer contexts, thereâ€™s a limit to how much benefit we can get. Even for large N, N-Gram models still struggle to capture long-term relationships between words that span across sentences or paragraphs. For example, in longer texts, dependencies between words far apart might be missed because the model only looks at the most recent N words.\n",
        "\n",
        "- 6. **Scalability Issues**\n",
        "    \n",
        "    - When dealing with larger datasets and higher values of N, scalability becomes a problem:\n",
        "        \n",
        "        - **Training takes longer:** Larger N-Gram models take more time to train, especially when working with huge text corpora.\n",
        "        \n",
        "        - **Slow predictions:** When we want the model to generate text or predict the next word, it takes longer to find the right N-Gram, slowing down the overall process.\n",
        "\n",
        "- 7. **Balancing Generalization and Specificity**\n",
        "    \n",
        "    - Finding the right balance between the size of N and the modelâ€™s ability to generalize is tricky:\n",
        "        \n",
        "        - **Smaller N:** If we choose a small N (like 2-grams or 3-grams), the model can capture simple patterns but might miss important longer-term relationships.\n",
        "        \n",
        "        - **Larger N:** With larger N (like 7-grams or 8-grams), the model might be too specific, remembering exact sequences rather than learning general language patterns. This reduces the modelâ€™s ability to work well on new, unseen data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 4.1: **Perplexity Criterion** <a name=\"perplexity-criterion\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Perplexity** is a common evaluation metric used in language models to measure how well a model predicts a sample of text. It provides an indication of how *uncertain* or *confused* a model is when making predictions about the next word in a sequence.\n",
        "\n",
        "\n",
        "- **Interpretation of Low Perplexity**\n",
        "    \n",
        "    - When a language model has **low perplexity** on a given text, it indicates:\n",
        "        \n",
        "        - The model is **confident in its predictions**. It assigns higher probabilities to the correct next word in the sequence.\n",
        "        \n",
        "        - The model is well-**aligned with the underlying structure** of the text and has learned the patterns of the language effectively.\n",
        "        \n",
        "        - It suggests that the language model can generate **fluent and coherent** text because it is less \"surprised\" by the actual next words in the sequence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 4.2: **Perplexity on Hafez & Modern Poem** <a name=\"Pre_NGRAM_Compares\"> </a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_text_perplexity(encoded_text, language_model):\n",
        "    filtered_text = [token for token in encoded_text if token != '[UNK]']\n",
        "    token_count = len(filtered_text) - language_model.order\n",
        "    if token_count > 0:\n",
        "        total_log_prob = 0\n",
        "        for idx in range(token_count):\n",
        "            ngram_prefix = filtered_text[idx:idx + language_model.order]\n",
        "            ngram_prob = language_model.probability_of(ngram_prefix)\n",
        "            if ngram_prob > 0:\n",
        "                total_log_prob += math.log(ngram_prob)\n",
        "            else:\n",
        "                total_log_prob += math.log(1e-7)\n",
        "        return math.exp(-total_log_prob / token_count)\n",
        "    return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_average_perplexity(file_path, description, language_model, tokenizer):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        lines = [line.strip() for line in file.readlines()]\n",
        "    perplexities = []\n",
        "    for line in tqdm(lines, desc=f\"Calculate Perplexity for {description}\", total=len(lines)):\n",
        "        line = line.replace(\"\\n\", \"\").replace(\".\", \"\")\n",
        "        encoded_line = tokenizer.encode(line).tokens\n",
        "        perplexity = compute_text_perplexity(encoded_line, language_model)\n",
        "        if perplexity is not None:\n",
        "            perplexities.append(perplexity)\n",
        "    if perplexities:\n",
        "        return sum(perplexities) / len(perplexities)\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "hafez_path = rXXX\n",
        "modern_poet_path = rXXX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4-GRAM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = models[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4-GRAM-Hafez** Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calculate Perplexity for Hafez Poetry: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14063/14063 [00:01<00:00, 11534.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average perplexity for Hafez corpus: 5243.474487870375\n"
          ]
        }
      ],
      "source": [
        "avg_perplexity_hafez = calculate_average_perplexity(hafez_path, \"Hafez Poetry\", model, tokenizer)\n",
        "print(f\"\\nAverage perplexity for Hafez corpus: {avg_perplexity_hafez}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4-GRAM-Modern** Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calculate Perplexity for Modern Poetry: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4400/4400 [00:30<00:00, 143.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average perplexity for modern poetry corpus: 1930.1075289168366\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "avg_perplexity_modern = calculate_average_perplexity(modern_poet_path, \"Modern Poetry\", model, tokenizer)\n",
        "print(f\"\\nAverage perplexity for modern poetry corpus: {avg_perplexity_modern}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**8-GRAM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = models[2] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**8-GRAM-Hafez** Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calculate Perplexity for Hafez Poetry: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14063/14063 [00:00<00:00, 22495.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average perplexity for Hafez corpus: 13612.503459420896\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "avg_perplexity_hafez = calculate_average_perplexity(hafez_path, \"Hafez Poetry\", model, tokenizer)\n",
        "print(f\"\\nAverage perplexity for Hafez corpus: {avg_perplexity_hafez}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4-GRAM-Modern** Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calculate Perplexity for Modern Poetry: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4400/4400 [00:43<00:00, 102.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average perplexity for modern poetry corpus: 1942.6012448577587\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "avg_perplexity_modern = calculate_average_perplexity(modern_poet_path, \"Modern Poetry\", model, tokenizer)\n",
        "print(f\"\\nAverage perplexity for modern poetry corpus: {avg_perplexity_modern}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**BiGRAM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = models[0] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**BiGRAM-Hafez** Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calculate Perplexity for Hafez Poetry: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14063/14063 [00:01<00:00, 9650.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average perplexity for Hafez corpus: 2770.3479519465773\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "avg_perplexity_hafez = calculate_average_perplexity(hafez_path, \"Hafez Poetry\", model, tokenizer)\n",
        "print(f\"\\nAverage perplexity for Hafez corpus: {avg_perplexity_hafez}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**BiGRAM-Modern** Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calculate Perplexity for Modern Poetry: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4400/4400 [00:26<00:00, 163.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average perplexity for modern poetry corpus: 2007.486166396677\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "avg_perplexity_modern = calculate_average_perplexity(modern_poet_path, \"Modern Poetry\", model, tokenizer)\n",
        "print(f\"\\nAverage perplexity for modern poetry corpus: {avg_perplexity_modern}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 4.A:**Perplexity Analysis** <a name='Anayze_Perplex'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **2-GRAM** Model \n",
        "    \n",
        "    - Shows the lowest perplexity among the models, suggesting minimal confusion in next-word predictions due to its limited contextual scope.\n",
        "\n",
        "- **4-GRAM** Model \n",
        "    \n",
        "    - Displays a moderate perplexity level, balancing accuracy and confusion effectively.\n",
        "\n",
        "- **8-GRAM** Model\n",
        "    \n",
        "    - Has the highest perplexity, potentially due to the complexities involved in its training data and the need for more memory to predict subsequent words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Shah-Nameh, Ferdowsi & Hafez & Modern Poetry**\n",
        "\n",
        "    - **Linguistic & Stylistic** Differences between the **epic style of Shahnameh** and the **lyrical poetry of Hafez**, which is **older** in the **Persian literary tradition** and includes **more archaic** and **Arabic-influenced vocabulary**, are profound, especially compared to **modern poetry**. \n",
        "    \n",
        "    - The **higher perplexity in Hafez's dataset** could stem from these **linguistic disparities**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbICV8VBYnm6"
      },
      "source": [
        "## **Chapter 3: N-Gram as a Classifier** <a name=\"Chapter-3\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44h4kmk8m0vC"
      },
      "source": [
        "### Part 1.1: **N-Gram As a Classifier** <a name=\"NGRAM_Classifier\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **N-gram models** are typically used in language modeling, but they can also serve as a powerful tool for **text classification**. Here's how n-grams can function as a classifier:\n",
        "\n",
        "- **N-grams in Text Classification**\n",
        "    \n",
        "    In text classification tasks, the goal is to assign a label (or class) to a given text based on its content. N-grams (sequences of *n* words or tokens) capture local context within a document, making them useful features for determining the topic, sentiment, or category of the text.\n",
        "\n",
        "- **Steps to Use N-grams as a Classifier:**\n",
        "\n",
        "    - **Text Representation:**\n",
        "        \n",
        "        - First, break down the input text into n-grams (e.g., unigrams, bigrams, trigrams).\n",
        "        \n",
        "        - Each n-gram represents a feature of the text. For example, in a sentiment analysis task, common bigrams like \"not good\" or \"very happy\" can strongly indicate the sentiment.\n",
        "\n",
        "    - **Feature Extraction:**\n",
        "        \n",
        "        - Once the text is tokenized into n-grams, a vectorized representation of the document is created, often using methods like **Bag of N-grams** or **TF-IDF**. This results in a numerical vector where each dimension corresponds to the frequency or importance of a particular n-gram in the text.\n",
        "\n",
        "    - **Training the Classifier:**\n",
        "        \n",
        "        - A classifier (such as Naive Bayes, SVM, or Logistic Regression) is then trained on these n-gram features across a labeled dataset.\n",
        "        \n",
        "        - The classifier learns which n-grams are indicative of specific classes. For example, in a spam detection task, the bigram \"free money\" might be associated with the \"spam\" class.\n",
        "\n",
        "    - **Making Predictions:**\n",
        "        \n",
        "        - When classifying new texts, the n-gram-based classifier looks at the n-grams in the input and uses the learned model to predict the class label.\n",
        "        \n",
        "        - The classifier can output the probability of the text belonging to each class based on the presence or absence of specific n-grams."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 1.2: **Big N & Low Data** <a name=\"bign_lowdata\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "- **Data Sparsity**\n",
        "    \n",
        "    - One of the most significant problems when increasing **n** in n-gram models with small datasets is **data sparsity**. As **n** increases, the number of possible n-grams grows exponentially, but the amount of available data remains fixed. This causes several issues:\n",
        "        \n",
        "        - **Fewer Observations:** Many of the larger n-grams will not appear frequently in the dataset. In extreme cases, some n-grams might not appear at all, leading to an inability to estimate probabilities for unseen n-grams.\n",
        "        \n",
        "        - **Overfitting Risk:** With more n-grams than data points, the model may overfit the small number of observed n-grams, capturing noise rather than meaningful patterns in the data.\n",
        "\n",
        "\n",
        "- **Increased Computational Complexity**\n",
        "    \n",
        "    - As **n** increases, the number of possible n-gram combinations grows exponentially. This leads to an increase in:\n",
        "        \n",
        "        - **Memory Requirements:** Storing large n-gram tables requires more memory, which becomes problematic when the dataset is small.\n",
        "        \n",
        "        - **Computational Cost:** Estimating probabilities for an increasing number of n-grams, especially with smoothing techniques, becomes computationally expensive with limited data.\n",
        "\n",
        "\n",
        "- **Poor Generalization**\n",
        "    \n",
        "    - When data is limited, increasing **n** leads to **poor generalization**. The model becomes too specific to the training data and may fail to handle unseen data effectively.\n",
        "       \n",
        "        - **Unseen N-grams:** Larger n-grams are more likely to be unseen during training. Without sufficient data, the model struggles to predict or assign probabilities to these unseen n-grams, making it less robust.\n",
        "        \n",
        "        - **Longer Dependencies:** While larger n-grams capture longer dependencies between words, this is only beneficial if the data is sufficient to observe these dependencies. With limited data, such long dependencies are rarely captured.\n",
        "\n",
        "- **Smoothing Issues**\n",
        "    \n",
        "    - With limited data, larger n-grams often result in many unseen or low-frequency n-grams. This forces the model to rely heavily on **smoothing techniques** (e.g., Laplace, Kneser-Ney), which distribute some probability mass to unseen n-grams. However, these techniques are not always perfect:\n",
        "    \n",
        "    - **Over-reliance on Smoothing:** As n-grams increase, the model may assign artificially inflated probabilities to unseen or rare n-grams, which can lead to inaccurate predictions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 2.1: **BPE Tokenizer** <a name=\"BPE_Tokenizer\"></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tokenizers import CharBPETokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_file_path = rXXX\n",
        "reviews_dataframe = pd.read_csv(input_file_path)\n",
        "reviews_dataframe['Enhanced_Review'] = reviews_dataframe['Text'].apply(lambda text: f\"<start> {text} <end>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "complete_text_data = '\\n'.join(reviews_dataframe['Enhanced_Review'])\n",
        "with open('training_corpus.txt', 'w', encoding='utf-8') as text_file:\n",
        "    text_file.write(complete_text_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "review_tokenizer = CharBPETokenizer()\n",
        "review_tokenizer.train(files=['training_corpus.txt'], vocab_size=5000, min_frequency=2, special_tokens=['<start>', '<end>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 2.2: **Tokenize the Dataset** <a name=\"Tokenize_BPE\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews_dataframe['Tokenized_Review'] = reviews_dataframe['Enhanced_Review'].apply(lambda review: review_tokenizer.encode(review).tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data, test_data = train_test_split(reviews_dataframe, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 3.1: **N-GRAM & Classification** <a name=\"Classification_NGRAM\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "grouped_data = train_data.groupby('Suggestion')\n",
        "ngram_frequencies = defaultdict(lambda: defaultdict(int))\n",
        "for label, group in grouped_data:\n",
        "    all_tokens = [token for review in group['Tokenized_Review'] for token in review]\n",
        "    for n in [2, 3]:\n",
        "        ngrams = [tuple(all_tokens[i:i+n]) for i in range(len(all_tokens)-n+1)]\n",
        "        for ngram in ngrams:\n",
        "            ngram_frequencies[label][ngram] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_probabilities(tokens, model, n):\n",
        "    ngram_probs = [model.get(tuple(tokens[i:i+n]), 0) + 1 for i in range(len(tokens) - n + 1)]\n",
        "    total_ngrams = sum(model.values()) + len(model) * (len(tokens) - n + 1)\n",
        "    return np.prod(ngram_probs) / total_ngrams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 3.2: **BiGram, TriGram** <a name=\"SplitData_32Gram\"></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Classifying: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 653/653 [00:30<00:00, 21.42it/s]\n"
          ]
        }
      ],
      "source": [
        "for index, row in tqdm(test_data.iterrows(), total=len(test_data), desc=\"Classifying\"):\n",
        "    tokens = row['Tokenized_Review']\n",
        "    bi_gram_probs = []\n",
        "    tri_gram_probs = []\n",
        "\n",
        "    for label, freqs in ngram_frequencies.items():\n",
        "        bi_gram_prob = evaluate_probabilities(tokens, {k: v for k, v in freqs.items() if len(k) == 2}, 2)\n",
        "        tri_gram_prob = evaluate_probabilities(tokens, {k: v for k, v in freqs.items() if len(k) == 3}, 3)\n",
        "        bi_gram_probs.append(bi_gram_prob)\n",
        "        tri_gram_probs.append(tri_gram_prob)\n",
        "        \n",
        "    best_bi_class = list(ngram_frequencies.keys())[np.argmax(bi_gram_probs)]\n",
        "    best_tri_class = list(ngram_frequencies.keys())[np.argmax(tri_gram_probs)]\n",
        "    test_data.at[index, 'Predicted_Bi_Class'] = best_bi_class\n",
        "    test_data.at[index, 'Predicted_Tri_Class'] = best_tri_class\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 3.3: **Criterion on Models** <a name=\"Criterion_Models\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "actual_classes = test_data['Suggestion']\n",
        "predicted_bi = test_data['Predicted_Bi_Class']\n",
        "predicted_tri = test_data['Predicted_Tri_Class']\n",
        "conf_matrix_bi = confusion_matrix(actual_classes, predicted_bi)\n",
        "conf_matrix_tri = confusion_matrix(actual_classes, predicted_tri)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "accuracy_bi = accuracy_score(actual_classes, predicted_bi) * 100\n",
        "accuracy_tri = accuracy_score(actual_classes, predicted_tri) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of 2-Gram Model: 46.09%\n",
            "Accuracy of 3-Gram Model: 58.35%\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy of 2-Gram Model: {accuracy_bi:.2f}%\")\n",
        "print(f\"Accuracy of 3-Gram Model: {accuracy_tri:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "recall_bi = recall_score(actual_classes, predicted_bi, average=None)\n",
        "recall_tri = recall_score(actual_classes, predicted_tri, average=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recall of 2-Gram Model (per class): [0.53164557 0.28125    0.26506024]\n",
            "Recall of 3-Gram Model (per class): [0.71308017 0.25       0.22891566]\n"
          ]
        }
      ],
      "source": [
        "print(f\"Recall of 2-Gram Model (per class): {recall_bi}\")\n",
        "print(f\"Recall of 3-Gram Model (per class): {recall_tri}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "precision_bi = precision_score(actual_classes, predicted_bi, average=None)\n",
        "precision_tri = precision_score(actual_classes, predicted_tri, average=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision of 2-Gram Model (per class): [0.74117647 0.17532468 0.13836478]\n",
            "Precision of 3-Gram Model (per class): [0.76643991 0.20168067 0.20430108]\n"
          ]
        }
      ],
      "source": [
        "print(f\"Precision of 2-Gram Model (per class): {precision_bi}\")\n",
        "print(f\"Precision of 3-Gram Model (per class): {precision_tri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 3.4: **Result Analysis** <a name=\"Analysis\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **2-GRAM(BiGRAM):**\n",
        "\n",
        "    - **Accuracy:** 46.09%\n",
        "\n",
        "    - **ReCall:** \n",
        "\n",
        "        - **Class 0:** 53.16% \n",
        "    \n",
        "        - **Class 1** 28.12%\n",
        "\n",
        "        - **Class 2:** 26.51%\n",
        "\n",
        "    - **Precision:** \n",
        "\n",
        "        - **Class 0:** 74.12%\n",
        "\n",
        "        - **Class 1:** 17.53%\n",
        "\n",
        "        - **Class 2:** 13.84%\n",
        "\n",
        "\n",
        "- **3-GRAM(TriGRAM):**\n",
        "\n",
        "    - **Accuracy:** 58.35%\n",
        "\n",
        "        - An increase from 46.09% to 58.35% demonstrates the 3-Gram model's superior ability to correctly classify instances.\n",
        "\n",
        "    - **ReCall:** \n",
        "\n",
        "        - **Class 0:** 71.31% \n",
        "    \n",
        "        - **Class 1** 25.00%\n",
        "\n",
        "        - **Class 2:** 22.89%\n",
        "\n",
        "            - This model shows improvement across all classes, particularly notable in Class 0.\n",
        "    \n",
        "    - **Precision:** \n",
        "\n",
        "        - **Class 0:** 76.64%\n",
        "\n",
        "        - **Class 1:** 20.17%\n",
        "\n",
        "        - **Class 2:** 20.43%\n",
        "\n",
        "            - Improved precision metrics in the 3-Gram model indicate a higher ratio of correct predictions per class compared to the total predictions made."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**BiGRAM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 25.722222222222214, 'Predicted Class')"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1400x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(14, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.heatmap(conf_matrix_bi, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('2-Gram Prediction Confusion Matrix')\n",
        "plt.ylabel('Actual Class')\n",
        "plt.xlabel('Predicted Class')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Class 0:**\n",
        "    - **True Positive (TP):** 252 instances correctly predicted as class 0.\n",
        "\n",
        "    - **False Positive (FP):** 114 (classified as 1) + 108 (classified as 2) = 222 instances where class 0 was wrongly predicted.\n",
        "\n",
        "- **Class 1:**\n",
        "\n",
        "    - Given that the matrix for classes 1 and 2 aren't fully visible.\n",
        "\n",
        "- **Class 2:**\n",
        "\n",
        "    - The lighter colors in classes 1 and 2 suggest lower counts compared to class 0, indicating less accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The model seems well-tuned to recognize features of class 0\n",
        "\n",
        "    - Higher training instances\n",
        "\n",
        "    - Distinct features that define this class in the training dataset\n",
        "\n",
        "- High False Positives for class 0\n",
        "\n",
        "    - Many instances belonging to other classes are incorrectly identified as class 0\n",
        "\n",
        "    - impacts on classes 1 and 2\n",
        "\n",
        "    - Need to cleaning the data and balancing but we want to learn N-Gram how classifying :) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**TriGRAM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1400x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(14,5))\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.heatmap(conf_matrix_tri, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('3-Gram Prediction Confusion Matrix')\n",
        "plt.ylabel('Actual Class')\n",
        "plt.xlabel('Predicted Class')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Tri-Gram model has shown greater efficacy in correctly classifying different classes, especially noticeable in Class 0, where the number of correct identifications is substantially higher."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Class 0:**\n",
        "    \n",
        "    - **True Positive (TP):** 338 instances correctly predicted as class 0.\n",
        "    \n",
        "    - **False Positive (FP):** 78 (classified as 1) + 58 (classified as 2) = 136 instances where class 0 was wrongly predicted.\n",
        "\n",
        "- **Class 1 & 2:**\n",
        "    \n",
        "    - For classes 1 and 2, the exact number of TP is not visible but the lighter shades indicate fewer correctly classified instances compared to class 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Using N-gram models instead of classifiers with many parameters**\n",
        "\n",
        "    - **Limited Data:** When training data are scarce, simpler models like N-grams might perform better due to their uncomplicated nature.\n",
        "\n",
        "    - **Need for Speed:** N-gram models, due to their simpler structure, usually compute faster than deep learning models.\n",
        "\n",
        "    - **Resource Constraints:** In environments with Limited Resources such as Mobile Devices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Chapter 4: Image tokenization** <a name=\"Chapter-4\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 1.1: **Image Tokenization & Vision Transformer** <a name=\"IT_VT\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Tokenization in Vision Transformers (ViT)**\n",
        "\n",
        "- **How Images are Tokenized in Vision Transformers (ViT)**\n",
        "\n",
        "    - In ViT, images are processed in a way that's similar to how language models handle text. Instead of looking at the whole image at once like traditional models (CNNs), ViT breaks the image into smaller patches â€” imagine cutting a picture into small squares, like 16x16 pixel pieces. Each of these patches is treated like a \"word\" in a sentence.\n",
        "\n",
        "    - These patches are then flattened into 1D vectors and passed through a layer that reduces their dimensionality. This step creates \"tokens\" out of the patches, which is just a way of turning each patch into a format the transformer can understand. Just like a sentence is made of word tokens, the image is now made up of patch tokens.\n",
        "\n",
        "    - Since transformers don't know the position of each patch, we add positional information to tell the model where each patch belongs in the image. This is like giving each patch an address so the model knows where it came from.\n",
        "\n",
        "    - we also add a special classification token [CLS] at the beginning of the sequence.\n",
        "\n",
        "    - This method allows the ViT to capture global information from the entire image by focusing on the relationships between different patches, similar to how transformers capture relationships between words in a sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 1.2: **MNIST & KMeans** <a name=\"Kmeans\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict, Counter\n",
        "import random\n",
        "from sklearn.datasets import fetch_openml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_mnist_data():\n",
        "    mnist = fetch_openml('mnist_784', version=1)\n",
        "    data = mnist.data.values.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
        "    labels = mnist.target.astype('int')\n",
        "    return (data[:60000], labels[:60000]), (data[60000:], labels[60000:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_patches(data, patch_size=9, stride=9):\n",
        "    patches = tf.image.extract_patches(images=data, sizes=[1, patch_size, patch_size, 1], strides=[1, stride, stride, 1], rates=[1, 1, 1, 1], padding='VALID')\n",
        "    reshaped_patches = tf.reshape(patches, [-1, patch_size * patch_size]).numpy()\n",
        "    return reshaped_patches, patches.shape[1] * patches.shape[2] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_kmeans(patches, n_clusters=256):\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    kmeans.fit(patches)\n",
        "    return kmeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tokenize_with_kmeans(patches, kmeans):\n",
        "    tokens = kmeans.predict(patches)\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_ngram_model(tokens, labels, patches_per_image, n=4):\n",
        "    model = defaultdict(Counter)\n",
        "    for i in range(0, len(tokens) - n + 1, patches_per_image):\n",
        "        for j in range(patches_per_image - n + 1):\n",
        "            context = tuple(tokens[i + j:i + j + n])\n",
        "            label = labels[i // patches_per_image]  \n",
        "            model[context][label] += 1\n",
        "    print(\"N-gram model trained.\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 2.1: **4-GRAM** <a name=\"4Gram_Image\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_with_ngram(context, model):\n",
        "    context_tuple = tuple(context)\n",
        "    if context_tuple in model:\n",
        "        prediction = max(model[context_tuple], key=model[context_tuple].get)\n",
        "    else:\n",
        "        prediction = random.choice(range(10))  \n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def aggregate_predictions(test_tokens, ngram_model, patches_per_image, n=4):\n",
        "    image_predictions = []\n",
        "    for i in range(0, len(test_tokens), patches_per_image):\n",
        "        image_patches = test_tokens[i:i + patches_per_image]\n",
        "        patch_predictions = [predict_with_ngram(image_patches[j:j + n], ngram_model) for j in range(patches_per_image - n + 1)]\n",
        "        most_common_prediction = Counter(patch_predictions).most_common(1)[0][0]\n",
        "        image_predictions.append(most_common_prediction)\n",
        "    return image_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "(train_data, train_labels), (test_data, test_labels) = load_mnist_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_patches, patches_per_image_train = extract_patches(train_data)\n",
        "test_patches, patches_per_image_test = extract_patches(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "kmeans = train_kmeans(train_patches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_tokens = tokenize_with_kmeans(train_patches, kmeans)\n",
        "test_tokens = tokenize_with_kmeans(test_patches, kmeans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N-gram model trained.\n"
          ]
        }
      ],
      "source": [
        "ngram_model = train_ngram_model(train_tokens, train_labels, patches_per_image_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_predictions = aggregate_predictions(test_tokens, ngram_model, patches_per_image_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_labels = np.array(test_labels)\n",
        "assert len(test_labels) == len(image_predictions), \"Mismatched lengths between test labels and predictions.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 2.2: **Accuracy** <a name=\"accuracy\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model accuracy: 71.52%\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(test_labels, image_predictions)\n",
        "print(f\"Model accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 2.Plot: **Plots-Predictions** <a name=\"plot\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x1000 with 10 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    plt.imshow(test_data[i].reshape(28, 28), cmap='gray')\n",
        "    plt.title(f\"Label: {test_labels[i]}, Pred: {image_predictions[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **References:**<a name='ref'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    \n",
        "- https://chatgpt.com/share/67180066-595c-8012-83df-1bfd16ac37f0\n",
        "- https://www.knime.com/blog/sentiment-analysis-with-n-grams\n",
        "- https://github.com/nahbos/Data-Mining-on-DigiKala-datasets\n",
        "- https://github.com/zhpinkman/sentiment-analysis-digikala\n",
        "- https://arxiv.org/abs/2010.11929\n",
        "- https://github.com/Mofid-AI/persian-nlp-benchmark/blob/main/notebooks/sentiment-analysis/SentimentAnalysis_HooshvareLab_bert-fa-base-uncased-sentiment-digikala.ipynb\n",
        "- https://huggingface.co/learn/nlp-course/en/chapter6/6\n",
        "- https://medium.com/@atharv6f_47401/wordpiece-tokenization-a-bpe-variant-73cc48865cbf\n",
        "- https://www.sciencedirect.com/topics/computer-science/levenshtein-distance#:~:text=The%20Levenshtein%20distance%20is%20a%20string%20metric%20for%20measuring%20the,one%20word%20into%20the%20other.\n",
        "- https://www.geeksforgeeks.org/damerau-levenshtein-distance/\n",
        " "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
